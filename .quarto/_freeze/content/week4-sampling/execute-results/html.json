{
  "hash": "299ee102c548af5ae23792dce9da4371",
  "result": {
    "markdown": "---\ntitle: \"Sampling variability\"\nsubtitle: \"Frequency distributions of summary statistics under random sampling\"\nformat: \n  revealjs:\n    logo: img/poly-logo-2.jpg\n    footer: \"STAT218\"\n    smaller: true\n    mermaid:\n      theme: neutral\nexecute: \n  echo: false\n  warning: false\n  message: false\n---\n\n\n## Today's agenda\n\n\n::: {.cell}\n\n:::\n\n\nToday we'll focus on understanding sampling variability. This is a foundation for the development of inferential statistics.\n\n1.  Reading quiz \\[[2pm section](https://forms.office.com/r/gs613rUX1z)\\] \\[[4pm section](https://forms.office.com/r/f9asSVpc8y)\\]\n2.  \\[lecture/lab\\] Effect of sampling variability on summary statistics\n3.  \\[lecture/lab\\] Effect of sample size on sampling variability of summary statistics\n4.  The normal model\n\n## Inferential statistics\n\nConsider this descriptive finding from the FAMuSS study:\n\n::: columns\n::: {.column width=\"50%\"}\n\n::: {.cell}\n::: {.cell-output-display}\n![](week4-sampling_files/figure-revealjs/unnamed-chunk-2-1.png){width=480}\n:::\n:::\n\n:::\n\n::: {.column width=\"50%\"}\nMedian percent change by genotype:\n\n\n::: {.cell}\n::: {.cell-output-display}\n------------------\n  CC     CT    TT \n------ ------ ----\n 42.9   45.5   50 \n------------------\n:::\n:::\n\n\n*Subjects with genotype TT exhibited the largest median percent change in strength*\n:::\n:::\n\n**Inferential statistics** will allow us to address questions like:\n\n> Should we expect these differences to persist among the general population?\n\nTo do so we will need to articulate how samples relate to populations.\n\n## Sampling variability\n\nDifferent samples inevitably produce different outcomes. This is **sampling variation**:\n\n> If we re-run the study with new participants we'll get different results\n\nThe basis for statistical inference is distinguishing sampling variation from systematic variation.\n\nWhat we really want to know in the FAMuSS study:\n\n> Is the CC/TT/CT difference systematic in the population or an artefact of the sample?\n\nIn other words...\n\n-   was the result due to chance?\n-   or was it genuine?\n\n<!-- How often we'd observe a difference depends on a combination of factors: -->\n\n<!-- |             |                    |            | -->\n\n<!-- |-------------|--------------------|------------| -->\n\n<!-- |             | Sampling variation |            | -->\n\n<!-- | Effect size | **Low**            | **High**   | -->\n\n<!-- | **Low**     | Less often         | More often | -->\n\n<!-- | **High**    | More often         | Less often | -->\n\n## Random sampling\n\nIf we assume study units are sampled at random from a broader population, we can quantify how much summary statistics are expected to change from sample to sample.\n\n::: columns\n::: {.column width=\"50%\"}\n![](img/srs.png)\n:::\n\n::: {.column width=\"50%\"}\nA study **population** is a collection of all study units of interest.\n\nA **sample** is a subcollection from a population:\n\n-   *random* if study units have a known chance of inclusion in the sample\n-   *nonrandom* or *convenience* otherwise\n:::\n:::\n\nIn STAT218 we'll limit attention to **simple random samples**: each study unit in the population has an equal chance of inclusion in the sample.\n\n## A pretend population: NHANES data\n\nThe National Health and Nutrition Esamination Survey (NHANES) is an annual CDC program to collect health and nutrition data on the non-institutionalized civilian resident population of the United States. Here are a few variables:\n\n\n::: {.cell}\n::: {.cell-output-display}\n--------------------------------------------------------------------------------------\n subj.id   Gender   Age   Poverty   Pulse   BPSys1   BPDia1   TotChol   SleepHrsNight \n--------- -------- ----- --------- ------- -------- -------- --------- ---------------\n    1       male    34     1.36      70      114       88      3.49           4       \n\n    2       male    34     1.36      70      114       88      3.49           4       \n\n    3       male    34     1.36      70      114       88      3.49           4       \n\n    5      female   49     1.91      86      118       82       6.7           8       \n--------------------------------------------------------------------------------------\n:::\n:::\n\n\nI've selected 3,179 responses from the 2009-2010 survey; let's pretend the corresponding individuals form a population of interest.\n\n## Population distribution of a variable\n\nConsider the `TotChol` variable: total HDL cholesterol in mmol/L. It has a certain frequency distribution among the population that we'll call its *population distribution*.\n\n::: columns\n::: {.column width=\"40%\"}\n\n::: {.cell}\n::: {.cell-output-display}\n---------------------------------\n Population mean   Population SD \n----------------- ---------------\n      5.043            1.075     \n---------------------------------\n:::\n\n::: {.cell-output-display}\n![](week4-sampling_files/figure-revealjs/unnamed-chunk-5-1.png){width=480}\n:::\n:::\n\n:::\n\n::: {.column width=\"60%\"}\nIf we draw a random sample of 50 individuals...\n\n-   how closely will the sample align with the population distribution?\n-   how much will alignment change if we select a new sample?\n:::\n:::\n\n## Simulating sampling variability\n\nOpen the class activity `lab4-sampling`. The first part of this lab will load the NHANES data and provide you with a command for extracting a sample.\n\nYour task:\n\n1.  Have each person in your group extract a sample.\n2.  Calculate the mean and standard deviation.\n3.  Make a histogram.\n4.  Compare your results to the population.\n5.  Compare your results to each other.\n\nAfter you've had a chance to try in groups, we'll compare across the class.\n\n## Simulating sampling variability\n\n\n::: {.cell hash='week4-sampling_cache/revealjs/unnamed-chunk-6_1399ff7c110d6d0547b66db0310511b0'}\n\n:::\n\n\n::: columns\n::: {.column width=\"\\\"55%\"}\n\n::: {.cell}\n::: {.cell-output-display}\n![](week4-sampling_files/figure-revealjs/unnamed-chunk-7-1.png){width=768}\n:::\n:::\n\n:::\n\n::: {.column width=\"45%\"}\nYou should have observed something a bit like this.\n\nThese are 16 random samples with the sample mean indicated by the blue dashed line and the population mean indicated by the red solid line.\n\n-   frequency distributions differ a lot\n-   sample means vary a little\n-   most means are close to 5\n-   most standard deviations are near 1\n:::\n:::\n\n## Point estimation\n\nIt should seem plausible that the sample mean and standard deviation provide good estimates of the corresponding population quantities.\n\nWe call them point estimates of population parameters.\n\n| Parameter name     | Parameter notation | Point estimate |\n|--------------------|--------------------|----------------|\n| Mean               | $\\mu$              | $\\bar{x}$      |\n| Standard deviation | $\\sigma$           | $s_x$          |\n\nNow we can more formally describe statistical inference:\n\n-   a population parameter is any numeric characteristic of a population distribution\n-   an inference is a conclusion about the value of a population parameter based on point estimates *and their sampling variability*\n\nWe will focus initially on inferences about the mean $\\mu$ based on the point estimate $\\bar{x}$.\n\n## Measuring sampling variability\n\nIf we had means calculated from a large number of samples, we could make a frequency distribution for the values of the sample mean. This is called a **sampling distribution**.\n\n::: columns\n::: {.column width=\"40%\"}\n\n::: {.cell}\n::: {.cell-output-display}\n![](week4-sampling_files/figure-revealjs/unnamed-chunk-8-1.png){width=384}\n:::\n:::\n\n:::\n\n::: {.column width=\"60%\"}\n\n::: {.cell}\n::: {.cell-output-display}\n------------ ------- ------- ------ ------ -------\n **sample**     1       2      3      4       5   \n\n  **mean**    4.957   5.039   5.24   5.24   4.864 \n------------ ------- ------- ------ ------ -------\n:::\n:::\n\n\nCould measure the sampling variability using any measure of spread.\n\n-   standard deviation: 0.1513356\n\n*On average, the sample mean varies about the population mean by 0.15 mmol/L across simple random samples.*\n:::\n:::\n\n## Measuring sampling variability\n\nTheory indicates the standard deviation of the sample mean under random sampling is: $$\nSD(\\bar{x}) = \\frac{\\sigma}{\\sqrt{n}} \n\\qquad \\left(\\frac{\\text{population SD}}{\\sqrt{\\text{sample size}}}\\right)\n$$\n\nFor `TotChol`, the theoretical standard deviation is $SD(\\bar{x}) = \\frac{1.0747}{\\sqrt{50}} =$ 0.1519822.\n\nWe can estimate this quantity by replacing $\\sigma$ with the point estimate $s_x$, resulting in a **standard error** (estimated standard deviation): $$SE(\\bar{x}) = \\frac{s_x}{\\sqrt{n}} \n\\qquad \\left(\\frac{\\text{sample SD}}{\\sqrt{\\text{sample size}}}\\right)$$\n\n<!-- ## Summing up -->\n\n<!-- So far we have established two key points: -->\n\n<!-- -   the sample mean and standard deviation provide good point estimates of the corresponding population parameters under random sampling -->\n\n<!-- -   we can estimate the sampling variability of the mean under random sampling using its standard error $\\frac{s_x}{\\sqrt{n}}$ -->\n\n## Example with one sample\n\nThe simulations we've done so far have been a means of understanding just what a standard error is meant to capture; these are *not* a practicable method for measuring sampling variation.\n\nIn practice we'd simply compute a point estimate and standard error.\n\n::: columns\n::: {.column width=\"50%\"}\n\n::: {.cell}\n::: {.cell-output-display}\n![](week4-sampling_files/figure-revealjs/unnamed-chunk-10-1.png){width=768}\n:::\n:::\n\n:::\n\n::: {.column width=\"50%\"}\n\n::: {.cell}\n::: {.cell-output-display}\n----------------\n mean      se   \n------- --------\n 5.031   0.1396 \n----------------\n:::\n:::\n\n\n-   *The estimated mean total HDL cholesterol among the population is 5.031 mmol/L.*\n\n-   *The point estimate is expected to deviate by 0.1396 mmol/L on average from the population mean.*\n:::\n:::\n\n## Effect of sample size\n\nThe formula for the theoretical standard deviation of $\\bar{x}$ suggests that sampling variability diminishes with sample size. For example:\n\n\n::: {.cell}\n::: {.cell-output-display}\n-------- -------- ------- -------- --------- ---------\n **n**      10      50      100      1000      10000  \n\n **SD**   0.3398   0.152   0.1075   0.03398   0.01075 \n-------- -------- ------- -------- --------- ---------\n:::\n:::\n\n\nThe second section of `lab4-sampling` explores this. With your group:\n\n1.  Start with a sample size of 10.\n2.  Have each person draw a sample and compute the mean (or draw a series of samples and compute the mean each time).\n3.  Compare and observe how big the differences between your means are.\n4.  Repeat with a sample size of 1000.\n\nYou should see much less sampling variability after increasing $n$.\n\n## Visualizing effect of sample size\n\nGenerating a large number (10K) of samples allows us to approximate the sampling distribution for a variety of sample sizes.\n\n\n::: {.cell hash='week4-sampling_cache/revealjs/unnamed-chunk-13_bc72cf2456ddf01734789d707fbb7cb6'}\n\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](week4-sampling_files/figure-revealjs/unnamed-chunk-14-1.png){width=768}\n:::\n:::\n\n\n-   spread diminishes with sample size\n-   less variability among estimates from larger samples\n\nSo estimates are more accurate with more data, *assuming data are from a random sample.*\n\n## Normal model\n\nNotice that each simulated sampling distribution has produced a unimodal, symmetric, bell-shaped histogram.\n\n::: columns\n::: {.column width=\"60%\"}\nThe normal model is a theoretical frequency distribution characterized by two parameters:\n\n-   a mean (center)\n-   a standard deviation (spread)\n\nTheory dictates that the sampling distribution of the sample mean is well-approximated by a normal model under simple random sampling.\n:::\n\n::: {.column width=\"40%\"}\n\n::: {.cell}\n::: {.cell-output-display}\n![](week4-sampling_files/figure-revealjs/unnamed-chunk-15-1.png){width=768}\n:::\n:::\n\n:::\n:::\n\n*Based on discussion thus far, what do you think the model parameters might be?*\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}