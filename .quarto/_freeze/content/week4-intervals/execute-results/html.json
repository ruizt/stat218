{
  "hash": "4ae03621f8036c1f3586fcf71b8fb05f",
  "result": {
    "markdown": "---\ntitle: \"Interval estimation\"\nsubtitle: \"Adjusting estimates for sampling variation\"\nformat: \n  revealjs:\n    logo: img/poly-logo-2.jpg\n    footer: \"STAT218\"\n    smaller: true\n    mermaid:\n      theme: neutral\nexecute: \n  echo: false\n  warning: false\n  message: false\n---\n\n\n## Today's agenda\n\n\n::: {.cell}\n\n:::\n\n\n1. HW2 remarks/discussion\n2. [Lecture] A basic interval estimate for the mean\n3. [Lecture/lab] Exploring interval coverage\n4. [Lecture/lab] Comparing normal and $t$ models\n\n## From last time\n\n::: {.columns}\n\n::: {.column}\nUnder simple random sampling:\n\n- the sample mean provides a good point estimate of the population mean\n- its theoretical sampling variability is given by the standard deviation $\\frac{\\sigma}{\\sqrt{n}} = \\frac{\\text{population SD}}{\\sqrt{\\text{sample size}}}$\n- its estimated sampling variability is given by the standard error $\\frac{s_x}{\\sqrt{n}} = \\frac{\\text{sample SD}}{\\sqrt{\\text{sample size}}}$\n::: \n\n::: {.column}\n\n::: {.cell}\n::: {.cell-output-display}\n---------------------------------\n     &nbsp;       mean      sd   \n---------------- ------- --------\n   **sample**     5.031   0.9873 \n\n **population**   5.043   1.075  \n---------------------------------\n:::\n\n::: {.cell-output-display}\n![](week4-intervals_files/figure-revealjs/unnamed-chunk-2-1.png){width=960}\n:::\n:::\n\n:::\n\n:::\n\nSo in the example: the estimated mean total HDL cholesterol among the population is 5.031 mmol/L *and this point estimate is expected to deviate by 0.1396 mmol/L from the population mean on average across samples.*\n\n## Interval estimation\n\nA point estimate for the mean provides a guess at the exact value of the parameter; an interval estimate is **a range of plausible values**.\n\nIn general, an interval estimate is constructed from two main ingredients:\n\n1. point estimate\n2. standard error\n\nAnd one secret ingredient:\n\n3. a model for the sampling distribution of the point estimate\n\nThe general form of an interval estimate is: $$\\text{point estimate} \\pm \\text{margin of error}$$\n\n\n## Precision and coverage\n\n::: {.columns}\n\n::: {.column width=\"45%\"}\nIntervals have two main and attributes:\n\n- **precision** refers to how wide or narrow the interval is\n- **coverage** refers to how often, under random sampling, the interval captures the parameter of interest\n:::\n\n::: {.column width=\"55%\"}\nThese properties are inversely related:\n\n- if I say mean cholesterol is between 0 and 50 I'm almost certainly right, but the estimate is useless\n- if I say mean cholesterol is between 5.0299 and 5.0301, I've made a very precise guess, but I'm likely wrong (think about sampling variability)\n:::\n\n:::\n\n> An accurate interval should maintain high coverage while achieving practically useful precision. *This isn't always possible!*\n\n## An interval for the mean\n\nA common interval for the population mean is:\n$$\\bar{x} \\pm 2\\times SE(\\bar{x}) \\qquad\\text{where}\\quad SE(\\bar{x}) = \\left(\\frac{s_x}{\\sqrt{n}}\\right)$$\n\n::: {.columns}\n\n::: {.column}\nBy hand:\n$$5.031 \\pm 2\\times 0.1396 = (4.75, 5.31)$$\n:::\n\n::: {.column}\nIn R:\n\n::: {.cell}\n\n```{.r .cell-code}\nc(lwr = mean(samp) - 2*sd(samp)/sqrt(50), \n  upr = mean(samp) + 2*sd(samp)/sqrt(50))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     lwr      upr \n4.751348 5.309852 \n```\n:::\n:::\n\n:::\n\n:::\n\nThe precision is evident from the interval width (0.5611). But what about coverage?\n\n## Exploring interval coverage\n\nLet's carry on pretending that the NHANES data comprise a population.\n\nThe first section of `lab5-intervals` contains some simple commands to draw a sample and calculate an interval estimate.\n\n1. Each of you will generate an interval *based on a different sample*\n2. We'll tally how many of you obtained intervals capturing the population mean\n\nOur tally will give an approximate idea of the coverage.\n\n## More simulation\n\n::: {.columns}\n\n::: {.column width=\"65%\"}\nArtificially simulating a larger number of intervals provides a slightly better approximation of coverage. \n\n- at right, 100 intervals\n- 97% cover the population mean (vertical dashed line)\n\nWhat do you expect would happen to coverage if, for the same samples...\n\n- a wider margin of error (say, $3\\times SE$) were used?\n- a narrower margin of error (say, $1\\times SE$) were used?\n:::\n\n::: {.column width=\"35%\"}\n\n::: {.cell}\n::: {.cell-output-display}\n![](week4-intervals_files/figure-revealjs/unnamed-chunk-4-1.png){width=384}\n:::\n:::\n\n:::\n\n:::\n## So why 2 standard errors?\n\n::: {.columns}\n\n::: {.column}\nThe margin of error of $2\\times SE$ comes from the so-called \"empirical rule\".\n\n- under the normal model, 95% of values are within 2SD of center\n- so for 95% of samples, the sample mean is within 2SD of the population mean \n\nSo in theory, according to the normal model, $\\bar{x} \\pm 2\\times SD$ achieves 95% coverage.\n\n:::\n\n::: {.column}\n![](img/empirical-rule.png){width=500}\n:::\n\n:::\n\n*But we are using standard error (SE), not standard deviation (SD). Do we still get the same coverage using the normal model?*\n\n## Normal model coverage\n\n\n\n::: {.cell hash='week4-intervals_cache/revealjs/unnamed-chunk-5_48ab50698bfef7ce54e89f74aa06fb2a'}\n\n:::\n\n\n::: {.columns}\n\n::: {.column}\n\nAt right, the misses are compared between intervals calculated with SD (left) and SE (right) using the multiplier from the normal model on the same 10,000 simulated datasets with sample size $n = 15$.\n\n- SE misses more often\n- so the normal model produces *under-coverage*\n\n\n::: {.cell}\n::: {.cell-output-display}\n-----------------\n type   coverage \n------ ----------\n  sd     0.954   \n\n  se     0.9294  \n-----------------\n:::\n:::\n\n\n*What do you think: the multiplier should be [smaller/larger] to ensure 95% coverage.*\n\n::: \n\n\n::: {.column}\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](week4-intervals_files/figure-revealjs/unnamed-chunk-7-1.png){width=960}\n:::\n:::\n\n\n:::\n\n:::\n\n## A closer look at the normal model\n\nAn alternate but equivalent way to understand the normal model for the sampling distribution of $\\bar{x}$ is in terms of deviations. The following are equivalent:\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](week4-intervals_files/figure-revealjs/unnamed-chunk-8-1.png){width=960}\n:::\n:::\n\n\nThe expression $\\frac{\\bar{x} - \\mu}{\\sigma/\\sqrt{n}}$ measures the number of standard deviations from center.\n\n## Simulating deviations\n\nAnother way to check normal model coverage is to use deviations:\n\n1. Simulate many samples\n2. Compute scaled deviations\n3. Tally how many scaled deviations are between -2 and 2\n\nThe proportion of samples for which the scaled deviation is between -2 and 2 approximates the coverage. \n\nWe'll try it in the next part of the `lab5-intervals`. Hypotheses: \n\n- deviations scaled by SD should be between -2 and 2 95% of the time\n- deviations scaled by SE should be between -2 and 2 [*more/less*] than 95% of the time\n\n## The $t$ model\n\nWe're *actually* using $\\frac{\\bar{x} - \\mu}{s_x/\\sqrt{n}}$ to construct intervals, because we don't know $\\sigma$. \n\nThese deviations are better approximated by a $t$ model, which adjusts the normal model for the extra uncertainty that comes from estimating the standard deviation.\n\n::: {.columns}\n\n::: {.column width=\"40%\"}\nThe difference between models depends mainly on sample size:\n\n- behaves almost exactly the same for moderate to large samples\n- larger deviations from center for small samples\n- leads to larger multipliers for computing margin of error\n:::\n\n::: {.column width=\"60%\"}\n![Comparison of $t$ model with normal model for various degrees of freedom.](img/normal-t.png)\n:::\n\n:::\n\n## Model specification\n\nThe $t$ model is characterized by its *degrees of freedom*.\n\n- for interval estimates for the mean, $n - 1$ is used\n- depending on the degrees of freedom (*i.e.*, sample size), a different multiplier is applied to the standard error to obtain the margin of error\n\nThe multiplier is called a **critical value**, and can be found in R via:\n\n::: {.cell}\n\n```{.r .cell-code}\n# pseudo code -- replace coverage with desired level, e.g., 0.95\nqt((1 - coverage)/2, df = (n - 1), lower.tail = F)\n```\n:::\n\n\n- chosen to ensure a specified **nominal coverage level** (usually 95%)\n- higher nominal coverage levels utilize larger critical values, producing wider intervals\n\n\n## Model validation\n\nUsing the $t$ model should produce coverage closer to the nominal level compared with the normal model. Let's check through simulation.\n\n\n::: {.cell hash='week4-intervals_cache/revealjs/unnamed-chunk-10_6c437f91ecd5f0a6776d8df51e7c9e41'}\n\n:::\n\n\n::: {.columns}\n\n::: {.column}\nAt right, misses are compared between intervals using SE and critical values from the normal model (left) and $t$ model (right) constructed on the same 10,000 simulated datasets with sample size $n = 10$.\n\n\n::: {.cell}\n::: {.cell-output-display}\n-------------------\n model    coverage \n-------- ----------\n normal    0.9219  \n\n   t       0.9461  \n-------------------\n:::\n:::\n\n\nThe $t$ model produces coverage much closer to the nominal level.\n:::\n\n:::{.column}\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](week4-intervals_files/figure-revealjs/unnamed-chunk-12-1.png){width=960}\n:::\n:::\n\n\n:::\n\n:::\n\n\n## Calculations\n\nSo, to sum up, the general formula for an interval for a population mean is:\n$$\\bar{x} \\pm c \\times SE(\\bar{x}) \\quad\\text{where}\\quad SE(\\bar{x}) = \\frac{s_x}{\\sqrt{n}}$$\n\n::: {.columns}\n\n::: {.column width=\"50%\"}\n\nRules of thumb:\n\n- for moderate to large samples, use the normal model\n    + $c = 1$ for 68% coverage\n    + $c = 2$ for 95% coverage\n    + $c = 3$ for 99.7% coverage\n- for small sample sizes, use the $t$ model\n- when in doubt, use the $t$ model\n\n:::\n\n::: {.column width=\"50%\"}\nExact critical values in R:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# normal critical value\nc <- qnorm((1 - coverage)/2, lower.tail = F)\n\n# t critical value\nc <- qt((1 - coverage)/2, df = n - 1, lower.tail = F)\n```\n:::\n\n\nInterval calculation:\n\n::: {.cell}\n\n```{.r .cell-code}\n# pseudo code\nmean(data_vec) + c(-1, 1)*c*sd(data_vec)/sqrt(n)\n```\n:::\n\n\n:::\n\n:::\n\n## Interpretation\n\nAs we've seen, coverage pertains to how often an interval of a particular form captures the population parameter of interest across samples of a fixed size. Loosely speaking, this represents how often you'd be right if you were to fully replicate your study *ad infinitum*. \n\nThis leads to the following interpretation:\n\n> With [XX]% confidence, the mean [population parameter] is estimated to be between [lower bound] and [upper bound] [units].\n\nFor this reason, statisticians call interval estimates **confidence intervals**.\n\n## Revisiting initial example\n\n::: {.columns}\n\n::: {.column}\nSo in the example we began with:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# calculate 95% interval\nmean(samp) + c(-1, 1)*2*sd(samp)/sqrt(50)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 4.751348 5.309852\n```\n:::\n:::\n\n\n*With 95% confidence, the mean total HDL cholesterol is estimated to be between 4.751 and 5.31 mmol/L.*\n\nRemember, \"95% confidence\" refers to coverage under sampling variation.\n\n::: \n\n::: {.column}\n\n::: {.cell}\n::: {.cell-output-display}\n----------------\n mean      se   \n------- --------\n 5.031   0.1396 \n----------------\n:::\n\n::: {.cell-output-display}\n![](week4-intervals_files/figure-revealjs/unnamed-chunk-16-1.png){width=960}\n:::\n:::\n\n:::\n\n:::\n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}