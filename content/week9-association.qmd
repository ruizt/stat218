---
title: "Association in two-way contingency tables"
subtitle: "Chi-square and exact tests for independence in two-way tables"
format: 
  revealjs:
    logo: img/poly-logo-2.jpg
    footer: "STAT218"
    smaller: true
    mermaid:
      theme: neutral
execute: 
  echo: false
  warning: false
  message: false
html-math-method:
  method: mathjax
  url: "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"
---

```{r}
library(tidyverse)
library(oibiostat)
library(pander)
library(Sleuth3)
library(epitools)
```

## Today's agenda

1. [lecture/discussion] Tests for association in two-way tables
2. [discussion] Review project expectations
2. [activity] Project planning

## From last time: asthma

::: {.columns}

::: {.column}
A subsample of NHANES data were used to investigate whether asthma is more common in women than in men:

```{r practice problem 8}
asthma <- matrix(data = c(49, 781, 30, 769), 
               nrow = 2, 
               byrow = T, 
               dimnames = list(sex = c('female', 'male'),
                               asthma = c('asthma', 'no asthma'))
                )
asthma |> pander()
```

Possible inferences, so far:

- difference in proportions
- relative risk
- odds ratio

:::

::: {.column}
Point estimates:

- $\hat{p}_F - \hat{p}_M$ = `r prop.test(asthma)$est |> rev() |> diff() |> round(3)`
- $\widehat{RR}_\text{F:M}$ = `r riskratio(asthma, rev = 'both')$measure[2, 1] |> round(3)`
- $\widehat{OR}_\text{F:M}$ = `r oddsratio(asthma, rev = 'both')$measure[2, 1] |> round(3)`

Each measures association between sex and asthma differently.

> Can we develop a more general procedure to test for association?

:::

:::

## Association and independence

::: {.columns}

::: {.column}
Two events are **statistically independent** if
$$Pr(A \text{ and } B) = Pr(A)Pr(B)$$
Association between variables is a form of dependence.

Estimates of the probabilities of each outcome (M, F, asthma, no asthma) are:
```{r}
asthma.aug <- rbind(asthma, total = colSums(asthma)) |>
  cbind(total = c(rowSums(asthma), sum(asthma)))

(asthma.aug/sum(asthma)) |> pander()
```

:::

::: {.column}
> If sex and asthma were independent variables, the (true) probabilities in the table would be the product of the (true) marginal probabilities. 

<!-- For instance: -->
<!-- $$Pr(\text{asthma and female}) = Pr(\text{asthma})\times Pr(\text{female})$$ -->

If there is no association between sex and asthma, we would expect, *e.g.*:
$$\begin{align*}
\hat{p}_{FA} &\approx \hat{p}_F \times\hat{p}_A \\
0.03008 &\approx 0.5095 \times 0.0485
\end{align*}$$

:::

:::

## Expected counts

If the row and column variables are independent, then we would expect 
$$p_{ij} = p_i \times p_j 
\quad\Longleftrightarrow\quad n_{ij} = \frac{n_{i\cdot} \times n_{\cdot j}}{n}$$

::: {.columns}

::: {.column width="40%"}
Actual counts:

&nbsp; | O1 | O2 | total
---+---+---+---
**G1** | $n_{11}$ | $n_{12}$ | $\color{red}{n_{1\cdot}}$
**G2** | $n_{21}$ | $n_{22}$ | $\color{orange}{n_{2\cdot}}$
**total** | $\color{blue}{n_{\cdot 1}}$ | $\color{green}{n_{\cdot 2}}$ | $n$
:::

::: {.column width="60%"}
Expected counts under independence:

&nbsp; | O1 | O2 | total
---+---+---+---
**G1** | $\hat{n}_{11} = \frac{\color{red}{n_{1\cdot}} \color{black}{\times} \color{blue}{n_{\cdot 1}}}{n}$ | $\hat{n}_{12} = \frac{\color{red}{n_{1\cdot}} \color{black}{\times} \color{green}{n_{\cdot 2}}}{n}$ | $\color{red}{n_{1\cdot}}$
**G2** | $\hat{n}_{21} = \frac{\color{orange}{n_{2\cdot}} \color{black}{\times} \color{blue}{n_{\cdot 1}}}{n}$ | $\hat{n}_{22} = \frac{\color{orange}{n_{2\cdot}} \color{black}{\times} \color{green}{n_{\cdot 2}}}{n}$ | $\color{orange}{n_{2\cdot}}$
**total** | $\color{blue}{n_{\cdot 1}}$ | $\color{green}{n_{\cdot 2}}$ | $n$

:::

:::


## Expected counts: asthma example

::: {.columns}

::: {.column}
Actual counts:
```{r}
asthma.aug |> pander()
```
:::

::: {.column}
Expected counts under $H_0$:

```{r}
asthma.exp <- ((asthma.aug[1:2,3]%*%t(asthma.aug[3, 1:2]))/sum(asthma))
rownames(asthma.exp) <- rownames(asthma)
asthma.exp.aug <- rbind(asthma.exp, total = colSums(asthma.exp)) |>
  cbind(total = c(rowSums(asthma.exp), sum(asthma.exp)))
asthma.exp.aug |> pander()
```

:::

:::

> How should we quantify the overall difference of the expected counts from actual counts?

## The chi-square statistic

A measure of the amount by which actual counts differ from expected counts under independence is the **chi** (pronounced /ˈkaɪ ) **square statistic**:

$$\chi^2 = \sum_{ij} \frac{\left(n_{ij} - \hat{n}_{ij}\right)^2}{\hat{n}_{ij}} 
\qquad\left(\sum_\text{all cells} \frac{(\text{observed} - \text{expected})^2}{\text{expected}}\right)$$

::: {.columns}

::: {.column}
Under $H_0$, and provided that no expected counts are too small:

- the $\chi^2$ statistic has a sampling distribution that can be approximated 
- approximation is by a chi-square model with 1 degree of freedom
:::

::: {.column}

![Figure: chi-square models](img/chisq.png)
:::

:::

## Computing the chi-square statistic

::: {.columns}

::: {.column}
Cell-wise calculation:

------------------------------------------------------------------------------
   &nbsp;     asthma                           no asthma 
------------ -------------------------------- --------------------------------
 **female**   $\frac{(49 - 40.25)^2}{40.25}$  $\frac{(781 - 789.7)^2}{789.7}$  

  **male**    $\frac{(30 - 38.75)^2}{38.75}$  $\frac{(769 - 760.3)^2}{760.3}$   
------------------------------------------------------------------------------
:::

::: {.column}
Result:
```{r}
pander((asthma - asthma.exp)^2/asthma.exp)
```
:::

:::

Chi-square statistic: 
$$\chi^2 = 1.901 + 0.09691 + 1.975 + 0.1007 = 4.074$$

> If this statistic is sufficiently large relative to the model, the data are unlikely to have come from independent variables

## A test for independence

By comparing expected and actual counts, we can test the hypotheses:
$$\begin{cases} H_0: \text{asthma} \perp \text{sex} \quad\text{(no association)} \\ 
H_A: \neg(\text{asthma} \perp \text{sex}) \quad\text{(association)}\end{cases}$$

::: {.columns}

::: {.column}

$p$-value calculation: 

$$P(\chi^2_1 > \chi^2_\text{obs})$$
Interpretation: the frequency with which we'd see a chi-square statistic at least as large as observed if in fact the row and column variables are independent.
:::

::: {.column}
```{r, echo = T}
pchisq(4.074, df = 1, lower.tail = F)
```
```{r, fig.width=8, fig.height=5}
par(mar = c(4, 4, 1, 1),
    cex = 1.75)
x <- seq(0.1, 6, length = 1000)
y <- dchisq(x, df = 1)
chistat <- 4.074
curve(dchisq(x, df = 1), from = 0.1, to = 6, n = 500,
xlab = expression(chi[1]^2), ylab = '',
yaxt = 'n', axes = F)
axis(side = 1, at = (0:6))
title(ylab = 'frequency', line = 0.5)
polygon(c(chistat, x[x>chistat], max(x)), c(0, y[x>chistat], 0), col="red", border = NA)
abline(v = 4.074, lty = 2, col = 'red')
legend(x = 'topright', 
       legend = c('4.35% of samples', '95.65% of samples'), 
       fill = c('red', 'white'))
```
:::

:::

## Putting together a few pieces

The chi-square test indicates whether the data provide evidence of an association between row and column variables. We may wish to combine this with inferences from last time, *e.g.*,

1. Test for independence
2. Estimate relative risk, odds ratio, or differences in probability

::: {.columns}

::: {.column}
```{r, echo = T}
riskratio(asthma, rev = 'both')[1:3]
```
:::

::: {.column}
- `chi.square = 0.0435`: the data provide sufficient evidence to reject the null hypothesis of no association
- `$measure`: it is estimated that women are 57.2% more likely than men to have asthma 

    + 95% CI: 0.9% -- 145.1% more likely
:::

:::

## Interpreting results

::: {.columns}

::: {.column}
```{r, echo = T}
riskratio(asthma, rev = 'both')[2:3]
```

A full narrative summary comprises:

1. General statement of findings
2. Interpretation of test of association
3. Interval and point estimate for relative risk, odds ratio, or other measure of association
:::

::: {.column}
> Results suggest a relationship between asthma and sex. Data from a random sample of U.S. adults provides moderate evidence against the null hypothesis that asthma prevalence is independent of sex in favor of the alternative that there is an association ($\chi^2$ = 4.074 on 1 degree of freedom, *p = 0.0435*). With 95% confidence, it is estimated that women are between 1.009 and 2.451 times as likely to have diagnosed asthma compared with men, with a point estimate of 1.57.

:::

:::

## Extending to $I \times J$ tables

The chi-square test can be used to test for association between categorical variables with an arbitrary number of categories.

::: {.columns}

::: {.column}
FAMuSS data:
```{r}
data(famuss)
tbl <- xtabs(~ race + actn3.r577x, data = famuss) 
tbl |> pander()
```
:::

::: {.column}
Expected counts:
```{r}
tbl.exp <- (rowSums(tbl)%*%t(colSums(tbl))/sum(tbl)) 
rownames(tbl.exp) <- rownames(tbl)
tbl.exp |> pander()
```
:::

:::

- expected counts and chi-square statistic are calculated exactly the same way
- degrees of freedom are now $(I - 1)\times(J - 1)$

## Extending to $I\times J$ tables

In detail:

---------------------------------------------------------------------------------------------------------------------
     &nbsp;       CC                                CT                                TT  
---------------- --------------------------------  --------------------------------  --------------------------------
 **African Am**   $\frac{(16 - 7.85)^2}{7.85}$     $\frac{(6 - 11.84)^2}{11.84}$     $\frac{(5 - 7.306)^2}{7.306}$  

   **Asian**      $\frac{(21 - 15.99)^2}{15.99}$    $\frac{(18 - 24.13)^2}{24.13}$    $\frac{(16 -14.88)^2}{14.88}$  

 **Caucasian**    $\frac{(125 - 135.8)^2}{135.8}$   $\frac{(216 - 204.9)^2}{204.9}$   $\frac{(126 - 126.4)^2}{126.4}$ 

  **Hispanic**     $\frac{(4 - 6.687)^2}{6.687}$    $\frac{(10 - 10.09)^2}{10.09}$     $\frac{(9 - 6.224)^2}{6.224}$  

   **Other**       $\frac{(7 - 6.687)^2}{6.687}$    $\frac{(11 - 10.09)^2}{10.09}$     $\frac{(5 - 6.224)^2}{6.224}$  
---------------------------------------------------------------------------------------------------------------------

Then:

$$\begin{cases} &\chi^2 = \sum \text{all cells above} = 19.4 \\
&P(\chi^2_{8} > 19.4) = 0.01286 \end{cases}
\quad\Longrightarrow\quad \text{reject hypothesis of no association}$$

## $\chi^2$ tests in R

::: {.columns}

::: {.column}
The calculation by hand is lengthy, but in R is simple:
```{r, echo = T}
# construct table
tbl <- table(famuss$race, famuss$actn3.r577x)

# compute test statistic and p-value
chisq.test(tbl)
```
:::

::: {.column}
> The data provide sufficiently strong evidence to reject the null hypothesis that genotype is independent of race in favor of the alternative that there is an association ($\chi^2$ = 19.4 on 8 degrees of freedom, *p = 0.01286*).

:::

:::

*Which genotype/race combinations are contributing most to this inferred association?*

- could still calculate relative risk or odds ratios relative to a single reference group in $I \times 2$ tables
- for multinomial data, need to look at 'residuals'

## Residuals in $\chi^2$ tests

::: {.columns}

::: {.column}
The **residual** for each cell is defined as a standardized difference between the observed and expected count:

$$r_{ij} = \frac{n_{ij} - \hat{n}_{ij}}{\sqrt{\hat{n}_{ij}}} $$

- $r_{ij} > 0$: observation exceeds expectation
- $r_{ij} < 0$: observation is under expectation
- large $|r_{ij}|$ explain the association
:::

::: {.column}
```{r, echo = T}
# store result of test
out <- chisq.test(tbl)

# display residuals
out$residuals |> pander()
```

:::

:::

> African American and Asian populations have higher CC and lower CT frequencies than would be expected if genotype were independent of race.

## Fisher's exact test

> If expected cell counts are small, an exact test should be used

::: {.columns}

::: {.column}
![](img/infusion.png)

Fisher's exact test provides an alternative approach when expected cell counts are small:

- assigns a probability to *the entire table* under the hypothesis of independence
- adds up the probabilities of all tables that are less likely than the observed one
:::

::: {.column}
![Figure: example of computing a one-sided $p$-value using Fisher's exact method.](img/fisher-onesided.png)
:::

:::

## Project planning

Review the project guidelines with your partner. Then:

1. Come up with three possible topics that each of you will research independently and write them down.
2. Identify a means of searching for case studies related to your topics. Where will you look?
3. Agree on how you'll communicate.
4. Make a plan to meet outside of class next week (set a time and date).

Your plan for your independent meeting should be to review what each of you found, agree on one case study, and determine who will prepare which parts of the written summary. 
