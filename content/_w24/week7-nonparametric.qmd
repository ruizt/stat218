---
title: "Nonparametric inference"
subtitle: "Alternatives to one- and two-sample *t* tests"
format: 
  revealjs:
    logo: img/poly-logo-2.jpg
    footer: "STAT218"
    smaller: true
    mermaid:
      theme: neutral
execute: 
  echo: false
  warning: false
  message: false
---

## Today's agenda

```{r}
library(tidyverse)
library(oibiostat)
library(Sleuth3)
library(pander)
library(perm)
library(RColorBrewer)
set.seed(21824)
ddt <- MASS::DDT
coul <- brewer.pal(8, "Reds") 
coul <- colorRampPalette(coul)(40)
sleep.wide <- sleep |> 
  spread(group, extra) |>
  mutate(diff = `1` - `2`)
sleep.diffs <- sleep.wide$diff
```

1. [lecture] One- and two-sample inference using ranks
2. [lecture] Permutation tests
3. [lab] Three applications of nonparametric tests 

## Remark

> Avoid over-interpreting one summary/graphic by checking alternatives

::: {.columns}

::: {.column}

```{r, fig.width = 5, fig.height = 3.5}
gss <- read_csv('tests/data/gss.csv')
boxplot(household.size ~ political.party, data = gss, horizontal = T)
```

- common error: "republicans had larger households"

:::

::: {.column}
```{r, fig.height = 5, fig.width = 4}
par(mfrow = c(2, 1),
    mar = c(3, 1, 3, 1))
filter(gss, political.party == 'rep') |> 
  pull(household.size) |> 
  hist(main = 'republican',
       xlab = 'household size',
       ylab = '',
       yaxt = 'n',
       xlim = c(0, 12))
filter(gss, political.party == 'dem') |> 
  pull(household.size) |> 
  hist(main = 'democrat',
       xlab = 'household size',
       ylab = '',
       yaxt = 'n',
       xlim = c(0, 12))

```
:::

:::

## Parametric inference

Recall the basis for our inferential procedures (intervals/tests) so far:

> the $t$ model approximates the sampling distribution of the $T$ statistic(s)

::: columns
::: {.column width="50%"}
```{r, fig.height = 3.5, fig.width = 5}
par(mar = c(4, 4, 2, 0.5),
    cex = 1.25,
    cex.axis = 0.8)
curve(dt(x, df = 21), 
      from = -5, to = 5,
      xaxt = 'n',
      yaxt = 'n',
      main = 't model',
      xlab = '',
      ylab = '',
      col = coul[40])
abline(h = 0)
for(i in seq(2, 20, by = 1)){
  curve(dt(x, df = i), 
      from = -5, to = 5,
      xaxt = 'n',
      yaxt = 'n',
      xlab = '',
      ylab = '',
      col = coul[i + 19],
      add = T)
}
title(xlab = expression(paste("T = ", 
                              frac(bar(x) - mu, SE(bar(x))), 
                              '  or  T = ', 
                              frac((bar(x) - bar(y)) - delta, SE(bar(x) - bar(y))))),
      line = 2.5)
title(ylab = 'sampling \n frequency', line = 1)
```
:::

::: {.column width="50%"}
This is an example of a **parametric** approach: it relies on a **distributional assumption**.

-   the *t* model is parametric distribution
-   $T$ exactly follows this model only when underlying population distribution(s) are normal

*What should be done if the assumption is not plausible?*

<!-- This relies on some underlying assumptions: -->

<!-- - observations are independent -->

<!-- - either... -->

<!--     + sample sizes are "large enough"  -->

<!--     + or population distributions are nearly normal -->
:::
:::

## Nonparametric procedures

Nonparametric procedures are **distribution-free** in the sense that they make no assumptions about the *specific form* of the underlying population distribution.

> This does *not* mean nonparametric methods are free of any assumptions whatsoever

Nonparametrics can provide useful alternatives in special circumstances:

-   parametric assumptions not plausible
-   inferences about population parameters besides means
-   small-sample settings
-   'narrow' inferences limited in scope to observed data rather than a population

We will cover two nonparametric approaches to one- and two-sample inference:

1.  Rank-based procedures
2.  Permutation procedures

## Rank-based procedures

> **Rank-based procedures** are inferential procedures that leverage sorted data and distributional symmetry or group exchangeability assumptions to test for location shifts.

Consider the DDT data (15 measurements of DDT in kale in ppm) again. Sorted:

```{r}
sort(ddt) |> pander()
```

Suppose you wish to test whether the 'center' is 3ppm. If you assume the population distribution is symmetric about *c*...

1.  How many observations would you expect to be smaller than *c*?
2.  How many observations are actually smaller than 3?
3.  Based on your answers to 1-2, do you think it is likely that *c = 3*?

## Signed rank test

> The **signed rank test** is an alternative to the one-sample *t* test that *assumes the population distribution is symmetric* to test hypotheses about its center *c*.

::: columns
::: {.column width="60%"}
Hypotheses: $$H_0: c = c_0 \quad\text{vs.}\quad H_A: c \mathrel{\substack{<\\\neq\\ >}} c_0$$ Procedure:

1.  \[center\] Calculate deviations $d_i = x_i - c_0$

2.  \[rank\] Sort and rank the absolute deviations $|d_i|$

    -   average ranks in case of ties
    -   drop zeros

3.  \[sum\] Add up the 'signed ranks' $\text{sign}(d_i) \times R_i$
:::

::: {.column width="40%"}
This produces the test statistic:

$$V = \sum_{i = 1}^n \text{sign}(d_i) \times R_i$$

Sampling distribution found using:

-   (exact) combinatorics
-   (approximate) probability theory

Reject if $V$ is sufficiently large in the direction of the alternative.
:::
:::

## Illustration: DDT data

::: columns
::: {.column width="40%"}
Signed rank calculations:

```{r}
ddt.sranks <- tibble(obs.num = 1:length(ddt),
       ddt = ddt) |>
  mutate(ddt.c = ddt - 3) |>
  arrange(abs(ddt.c)) |>
  mutate(signed.rank = sign(ddt.c)*rank(abs(ddt.c)))
ddt.sranks
```

Procedure:

1.  **Center** observations
2.  **Rank** absolute deviations
3.  **Sum** signed ranks
:::

::: {.column width="60%"}
Hypotheses:

$$H_0: c = 3 \quad\text{vs}\quad H_A: c > 3$$

Test statistic:

```{r}
ddt.sranks |>
  group_by(sign = as.character(factor(sign(ddt.c), 
                                      labels = c('negative', 'positive')))) |>
  summarize(sum = sum(signed.rank)) |>
  bind_rows(tibble(sign = '', sum = 103)) |>
  pander()
```

There are `r sum(sapply(0:15, function(x){choose(15, x)})) |> pander()` possible sign combinations; of these, only about 0.18% give a larger value of $V$.

> $p = 0.0018 < 0.05 \;\Rightarrow\; \text{reject } H_0$
:::
:::

## Signed rank test in R

The implementation in R looks and functions much like `t.test`:

::: columns
::: column
```{r, echo = T}
# signed rank test
wilcox.test(ddt, mu = 3, 
            alternative = 'greater',
            conf.int = T)
```

-   reports the sum of *positive* signed ranks
-   $p$ value is approximate with ties or zeros
-   pseudo-median ($\neq$ median) is a measure of center
:::

::: column
The technically accurate interpretation is given in terms of "center":

> The data provide strong evidence against the null hypothesis that the center of the distribution of DDT in kale is 3ppm in favor of the alternative hypothesis that the center exceeds 3ppm (signed rank test, *p = 0.001876*).

<!-- - the minimum $p$ value is $\frac{1}{\#\;\text{sign combinations}}$ = `r sprintf("%.8f",sum(sapply(0:15, function(x){choose(15, x)}))^(-1))` (depends on sample size) -->
:::
:::

## Minimum $p$ values

The $p$ value for the test is the proportion of all possible sign combinations that yield a $V$ larger/smaller than observed.

::: columns
::: {.column width="60%"}
```{r, fig.width = 6, fig.height = 5}
par(mar = c(4, 6, 1, 1),
    cex = 1.25)
min_p <- function(n){sum(sapply(0:n, function(i){choose(n, i)}))^(-1)}
x <- 5:20
y <- sapply(x, min_p)
plot(x, sqrt(y), 
     type = 'b', 
     yaxt = 'n', 
     ylab = '', 
     xlab = 'sample size')
axis(2, at = sqrt(seq((min(y)), (max(y)), length = 8)),
     labels = round(seq((min(y)), (max(y)), length = 8), 4),
     las = 1)
title(ylab = 'minimum p value', line = 4)
```
:::

::: {.column width="40%"}
-   fewer sign combinations for few observations
-   smallest possible $p$ value depends on sample size
-   don't expect small p-values in small-$n$ settings
:::
:::

## Paired differences

> For paired differences, the signed rank test tests for a difference in location between the groups.

The test assumes that both population distributions are symmetric and tests the hypotheses:

$$H_0: c_1 = c_2 \quad\text{vs}\quad H_A: c_1 \mathrel{\substack{<\\\neq\\ >}} c_2$$

-   $c_1$ is the center of group/population 1
-   $c_2$ is the center of group/population 2

## Paired difference example

::: columns
::: {.column width="50%"}
> Is drug 2 more effective than drug 1?

First few observations of sleep data:

```{r}
head(sleep.wide, 4) |> 
  rename(drug1 = `1`,
         drug2 = `2`) |>
  pander()
```

The signed rank test will test for a difference in location, assuming that the pairwise differences are symmetric about some central point.
:::

::: {.column width="50%"}
Hypotheses:

$$\begin{cases} H_0: c_\text{drug1} = c_\text{drug2} \\
H_A: c_\text{drug1} < c_\text{drug2}
\end{cases}$$

```{r echo=T}
wilcox.test(sleep.diffs, mu = 0,
            alternative = 'less',
            conf.int = T)
```

*Aside: what does* $V = 0$ mean?
:::
:::

## Checking assumptions

> For the signed rank test, the underlying distribution is assumed to be symmetric. 

Check the symmetry assumption graphically using histograms.

```{r, fig.width=6, fig.height = 2}
par(mfrow = c(1, 2),
    mar = c(5, 2, 3, 1),
    cex = 1)
hist(ddt, breaks = 5,
     main = 'DDT data',
     xlab = 'DDT in kale (ppm)',
     ylab = '',
     yaxt = 'n')
hist(sleep.diffs, breaks = 5,
     main = 'Sleep data',
     xlab = 'pairwise differences',
     ylab = '',
     yaxt = 'n')
```

It can be tricky with small sample sizes; don't be too sensitive to asymmetries. Both of these are acceptable.

## Rank sum test

> The **rank-sum test** is a two-sample rank-based inference procedure that tests for a difference in location from independent samples.

**Key idea:** if observations in both groups come from the same population distribution, then they should be exchangeable (*i.e.*, groupings don't matter).

::: columns
::: column
Assumptions:

-   observations are independent
-   the populations differ only by location

Hypotheses:

$$H_0: c_1 = c_2\quad\text{vs}\quad H_A: c_1 \mathrel{\substack{<\\\neq\\>}} c_2$$
:::

::: column
Procedure:

1.  \[pool\] Combine observations from both groups
2.  \[rank\] Sort and rank pooled observations
3.  \[sum\] Add up ranks in the smaller group

Reject if the sum is larger/smaller than expected.
:::
:::

## Checking assumptions

> The assumption for the rank sum test is that the distributions differ only by location.

If this is true, histograms should have the same shape and modes.

```{r, fig.width = 9, fig.height = 2}
par(mfrow = c(1, 3),
    mar = c(2, 2, 2, 1),
    cex = 1)
curve(dgamma(x, shape = 2, rate = 1), 
      from = 0, to = 10,
      xaxt = 'n', yaxt = 'n',
      xlab = '', ylab = '')
abline(v = 2, lty = 2)
curve(dgamma(x - 3, shape = 2, rate = 1), 
      from = 3, to = 10,
      xaxt = 'n', yaxt = 'n',
      xlab = '', ylab = '',
      add = T, col = 2)
abline(v = 5, lty = 2, col = 2)
title(ylab = 'frequency', line = 0.5)
title(xlab = 'values', line = 0.5)
title(main = 'assumptions met perfectly')

curve(dgamma(x, shape = 2, rate = 1), 
      from = 0, to = 10,
      xaxt = 'n', yaxt = 'n',
      xlab = '', ylab = '')
abline(v = 2, lty = 2)
curve(dgamma(x - 3, shape = 3, rate = 1), 
      from = 3, to = 10,
      xaxt = 'n', yaxt = 'n',
      xlab = '', ylab = '',
      add = T, col = 2)
abline(v = 6, lty = 2, col = 2)
title(ylab = 'frequency', line = 0.5)
title(xlab = 'values', line = 0.5)
title(main = 'assumptions reasonable')

curve(dgamma(x, shape = 2, rate = 1), 
      from = 0, to = 10,
      xaxt = 'n', yaxt = 'n',
      xlab = '', ylab = '')
abline(v = 2, lty = 2)
curve(dgamma(x, shape = 1, rate = 1/3), 
      from = 0, to = 10,
      xaxt = 'n', yaxt = 'n',
      xlab = '', ylab = '',
      add = T, col = 2)
abline(v = 3, lty = 2, col = 2)
title(ylab = 'frequency', line = 0.5)
title(xlab = 'values', line = 0.5)
title(main = 'assumptions not met')
```

In all of these cases, there is a (true) difference in location.

- if shape differs too much, the rank sum test should *not* be used
- can be hard to tell with small samples

## Your turn

> Is the rank sum test appropriate for comparing centers? 

::: {.columns}

::: {.column}

Out-of-state tuition costs from 26 public and 26 private universities.
```{r, fig.width=5, fig.height=4}
ex0332 %>%
  ggplot(aes(x = OutOfState)) +
  facet_wrap(~Type, nrow = 2, scales = 'free_y') +
  geom_histogram(aes(y = after_stat(density)),
                 alpha = 0.6, binwidth = 5000) +
  stat_density(aes(y = after_stat(density)), 
               bw = 6000, alpha = 0.2) +
  labs(y = '', x = 'tuition') +
  scale_y_continuous(labels = NULL, breaks = NULL) +
  scale_x_continuous(n.breaks = 5, limits = c(0, 50000)) +
  theme_minimal(base_size = 18) +
  theme(panel.grid = element_blank())
```
:::

::: {.column}
Deviations from expected cancer rates in CT in years with high and low sunspot activity.
```{r, fig.width=5, fig.height=4}
load('hw/data/cancer.RData')
cancer %>%
  ggplot(aes(x = delta)) +
  facet_wrap(~sunspot.activity, nrow = 2, scales = 'free_y') +
  geom_histogram(aes(y = after_stat(density)),
                 alpha = 0.6, bins = 8) +
  stat_density(aes(y = after_stat(density)), 
               bw = 0.2, alpha = 0.2) +
  labs(y = '', x = 'shift in cancer rate (per 100K)') +
  scale_y_continuous(labels = NULL, breaks = NULL) +
  scale_x_continuous(n.breaks = 5, limits = c(-0.5, 0.8)) +
  theme_minimal(base_size = 18) +
  theme(panel.grid = element_blank())
```
:::

:::

## Rank sum test in R

The `wilcox.test` function also implements the rank sum test.

::: {.columns}

::: {.column width="55%"}

```{r, echo=T}
wilcox.test(delta ~ sunspot.activity, data = cancer, 
            mu = 0, alternative = 'greater', 
            conf.int = T)
```

- $p$-value gives the percentage of possible rank allocations among the groups for which the rank sum is at least as favorable to $H_A$

    + computed by combinatorics
    + subject to minima depending on sample sizes

:::

::: {.column width="45%"}
> The data provide strong evidence against the hypothesis that the distribution of deviations from expected cancer rates in Connecticut does not differ according to sunspot activity in favor of a positive location shift associated with high sunspot activity (rank sum test, $p < 0.0001$).

:::

:::

## Use heuristics for rank procedures

Consider a rank-based procedure if...

- sample sizes are small
- you want to test for a location shift

Once you've decided to consider a rank test...

1. Determine test type (one-sample, paired, two-sample)
2. Check symmetry/similarity assumption graphically
3. Perform test

## Permutation tests

> Permutation tests are two-sample procedures that provide highly flexible alternatives to parametric tests based on exchangeability.

**Key idea**: if there is no difference between groups/populations, observations are *exchangeable* between groups.

::: {.columns}

::: {.column}

Procedure:

1. Randomly shuffle group assignments among the observations.
2. Calculate any group comparison.
3. Repeat many times.
4. Calculate proportion of shufflings for which the comparison is at least as large as the observed comparison in the direction of the alternative

::: 

::: {.column}
Permutation tests for differences in means are implemented by `permTS()`.
```{r, echo = T}
permTS(OutOfState ~ Type, data = ex0332, 
       alternative = 'greater')
```
:::

:::

## Lab: three end-to-end analyses

::: {.columns}

::: {.column width="40%"}
Cholesterol data:
```{r}
read_csv('labs/data/cholesterol.csv') |>
  head(2) |> pander()
```
Zinc and dietary supplements:
```{r}
ex0125 |>
  head(2) |> pander()
```
Sleep data:
```{r}
sleep.wide |>
  head(2) |>
  pander()
```

:::

::: {.column width="60%"}
Questions:

1. Are zinc concentrations (mg/ml) in the blood of rats lower among those that received a dietary supplement (group A) compared with those that did not receive the supplement group (B)?

2. Is there a difference in cholesterol associated with consuming oat bran compared with consuming corn flakes?

3. Does drug 2 produce more than 1 hour of additional sleep compared with drug 1?

Your task, for each dataset, is to (a) determine and perform the appropriate nonparametric test and (b) interpret the result accurately.

:::

:::

```{r, eval = F}
ex0428 |>
  ggplot(aes(x = Cross - Self)) +
  geom_histogram(bins = 10)

cholesterol <- read_csv('labs/data/cholesterol.csv')
cholesterol |> 
  ggplot(aes(x = Cholesterol)) + 
  geom_histogram(bins = 8) + 
  facet_wrap(~Diet)
wilcox.test(Cholesterol ~ Diet, 
            data = cholesterol, 
            alternative = 'greater')

sleep.wide |>
  rename(drug1 = `1`, drug2 = `2`) |>
  write_csv('labs/data/sleep.csv')

ex0428 |> write_csv('labs/data/darwin.csv')
```