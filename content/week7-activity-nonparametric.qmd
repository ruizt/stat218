---
title: "Week 7 activity: Nonparametric inference"
author: "STAT218"
author-title: "Course activity"
execute: 
  echo: true
  eval: true
  message: false
  warning: false
format: 
  html:
    toc: true
  docx:
    toc: false
prefer-html: true
embed-resources: true
---

```{r setup}
library(tidyverse)
load('data/brfss.RData')
load('data/temps.RData')
ddt <- MASS::DDT
```

In this activity you'll learn about nonparametric alternatives to the $t$ test for one and two means. The activity is organized much like a lab, but with extra narrative. You should read through the narrative at your own pace and try the exercises provided as you go. At the end there are two practice problems that you'll be expected to complete before next class.

### Background: parametric and nonparametric inference

Consider the basis for the inferences developed so far: under certain conditions (typically regularity of the underlying population distribution, assessed by checking histograms for unimodality and approximate symmetry) and with sufficient sample sizes, a model is specified for the sampling distribution of a test statistic. 

- inference for one mean: $t_{n - 1}$ model for the sampling distribution of $T = \frac{\bar{x} - \mu}{SE(\bar{x})}$
- inference comparing two means: $t_{\nu}$ model for the sampling distribution of $T = \frac{\bar{x} - \bar{y} - \delta}{SE(\bar{x} - \bar{y})}$
- inference comparing several means: $F_{k - 1, n - k}$ model for the sampling distribution of $F = \frac{MSG}{MSE}$

These are all what are known as *parametric models*, because they are specified through one or two parameters that determine their exact shape. The parameters in this case are the degrees of freedom terms -- $n - 1$ for the one-sample $t$ test, $\nu$ (usually estimated) for the two-sample $t$ test, and $k - 1$ and $n - k$ for the $F$ test.

As such, these procedures are examples of *parametric inference* -- inferences that utilize a parametric model for the data and/or test statistic.

When assumptions for parametric inference aren't tenable, or when a parametric model is not available, there are so-called **nonparametric** methods of inference: **methods that don't depend on a parametric model** such as the $t$ or $F$ models we've learned about in class.

We will consider specifically nonparametric procedures based on ranks, *i.e.*, ordering observations from smallest to largest. 

### Motivating examples

In practice, the situation that most often leads an analyst to consider rank-based nonparametric methods is that the assumptions for the $t$ test either don't hold or are difficult to assess.

Below are two such situations you've already encountered in this class.

#### Small sample sizes

When sample sizes are small, it's awkward to assess assumptions for parametric inference, because with few observations histograms can lack any discernible shape. For example, the most we can say about the following data on heart rates for 19 women and 20 men is that there are no evident outliers.

```{r motivation 1: small sample sizes}
heart.m <- temps |> filter(sex == 'male') |> pull(heart.rate)
heart.f <- temps |> filter(sex == 'female') |> pull(heart.rate)

par(mfrow = c(1, 2))
hist(heart.m)
hist(heart.f)
```

In practical terms, the $t$ test is likely still fine under these circumstances; however, some may wish to consider an inference for comparing heart rates between groups that doesn't depend on distributional assumptions.

#### Assumptions don't hold

On occasion you may go to check assumptions and find that they're clearly violated. For example, the pairwise differences between actual and desired weights from BRFSS respondents showed clear skewness and several large outliers. In that case, the sample size was big enough that we overlooked the issue, but it's not hard to imagine a similar situation cropping up with fewer observations.

Suppose you only had 12 observations that showed the same skew and had one big outlier:

```{r motivation 2: assumptions fail}
set.seed(51424)
weight.diff <- sample(brfss$weight - brfss$wtdesire, 12)
hist(weight.diff, breaks = 10)
```

Here the $t$ test isn't appropriate, and using it anyway would likely result in a true significance level, coverage, and power quite different from the nominal levels specified in the test, so it would be hard to trust the result. This is a great situation to use a rank-based nonparametric alternative.

### Inference on "location" (not mean)

The usual parametric inferences pertain to the population mean; not so with rank-based nonparametrics. Instead, these inferences pertain simply to "location". 

Often "location" is characterized in terms of the "center" of a distribution so that inferences can be interpreted in a manner similar to parametric tests and intervals. 

We will follow this convention and consider the hypotheses to be about the center(s) of the population model(s), denoted $c$. For example, the two-sided test of center would test the hypotheses:

$$
\begin{cases}
H_0: &c = c_0 \\
H_A: &c \neq c_0
\end{cases}
$$

For the two-sided test of difference in centers, we will test the hypotheses:

$$
\begin{cases}
H_0: &c_1 = c_2 \\
H_A: &c_1 \neq c_2
\end{cases}
$$

However, you should keep in mind that "location" is a more general notion that encompasses all measures of location of a distribution.

### One-sample inference: signed rank test

The basic premise of this test is that, if the population model is symmetric, its center should evenly divide the data.

::: callout-tip

## Warm up

Consider the following 15 measurements of DDT in kale in ppm in order from smallest to largest:

```{r signed rank test: warm up}
sort(ddt)
```

Suppose you wish to test whether the center $c$ of the population model is $c_0 = 3$ ppm and assume a symmetric population model.

1.  How many observations would you expect to be smaller than $c_0 = 3$ if 3ppm is in fact the center?
2.  How many observations are actually smaller than 3 ppm?
3.  Based on your answers to 1-2, do you think it is likely that in fact $c = 3$?
:::

::: {.callout-tip collapse="true"}

## Solution

If the population is symmetric about $c_0$, you'd expect roughly half of observations (`r length(ddt)/2`) to be smaller than 3ppm.

The actual number of observations smaller than 3ppm is:

```{r signed rank test: warmup solution}
# number of observations below 3
sum(ddt < 3)
```

This is much less than half, so it seems unlikely that the center is actually 3ppm.
:::

The signed rank test is a nonparametric alternative to the one-sample $t$ test applicable to any symmetric population model. The particular form of symmetry and presence of outliers do not affect the test.

#### Hypotheses

The test can be directional or two-sided, just like the $t$ test. Thus, the possible hypotheses are: 

$$
H_0: c = c_0 \quad\text{vs.}\quad H_A: c \mathrel{\substack{<\\\neq\\ >}} c_0
$$ 

#### Test procedure

While the intuition of the test is that half of observations should be smaller than the true center under population symmetry, the test statistic is not quite as direct as a tally of how many observations are below the hypothetical value. Instead, the procedure is as follows:

1.  \[center\] Calculate deviations $d_i = x_i - c_0$

2.  \[rank\] Sort and rank the absolute deviations $|d_i|$

    -   average ranks in case of ties
    -   drop zeros

3.  \[sum\] Add up the positive 'signed ranks' $\sum_{\text{sign}(d_i) > 0} r_i$

This produces the test statistic:

$$V = \sum_{i = 1}^n \text{sign}(d_i) \times R_i$$

::: callout-tip

## Check your understanding

Try working out the rank sum procedure manually using the DDT data -- it's small enough that you could jot down the steps on some scratch paper. See if you can calculate $V$.

To help, here are the deviations sorted smallest to largest:
```{r signed rank test procedure: check your understanding}
# calculate deviations
di <- ddt - 3
sort(di)
```

1. Start by writing the deviations in order of absolute value in a column. 
2. Then rank them 1-15 in an adjacent column. If there is a tie -- *e.g.*, two absolute deviations of 0.05 -- then assign them both the average of the ranks. For example, if 0.05 occurs twice in positions 2 and 3, then give them both rank 2.5.
3. Write down the sign of the deviation in a new column.
4. Then write down the "signed rank", or product of the sign and the rank, in a fourth column.
5. Add up the positive signed ranks. This is the signed rank statistic.

:::

::: {.callout-tip collapse="true"}
## Solution

This shows the steps in R, but don't worry about the codes; the output is meant to illustrate what you would do on paper to find the rank sum statistic.

```{r signed rank test procedure: check your understanding solution}
# this shows the steps, column by column; focus on output
ddt.srank <- tibble(di = di) |>
  mutate(abs.di = abs(di), 
         rank = rank(abs.di),
         sign = sign(di),
         signed.rank = sign*rank) |>
  arrange(abs.di)
ddt.srank

# signed rank statistic
vstat <- ddt.srank |> filter(sign > 0) |> pull(signed.rank) |> sum()
vstat
```
:::

#### $p$-values for the test

Just like other hypothesis tests, the signed rank test rejects if $V$ is sufficiently large in the direction of the alternative. 

A sampling distribution for $V$ can be found exactly using combinatorics, or approximated using probability theory. In this caseWe won't go into details about either approach, except to indicate that there is a sampling distribution for $V$ that we can use to obtain $p$-values in the same fashion that the $t_{n - 1}$ model was used to obtain $p$-values for the $t$ test.

In this case, there are `r sum(sapply(0:15, function(x){choose(15, x)}))` possible sign combinations; of these, only about 0.375% give a larger value of $V$. That provides a $p$-value for the test, and since $p = 0.0018 < 0.05$ we would reject $H_0$ at the 5% significance level. This result is interpreted as:

> The data provide strong evidence that the typical DDT concentration in kale is not 3ppm (signed rank statistic *V* = 111.5, *p* = 0.00375).

#### Implementation with `wilcox.test(...)`

The implementation in R looks and functions much like `t.test`:

```{r signed rank test: implementation}
# signed rank test at 1% level
wilcox.test(ddt, mu = 3, alternative = 'two.sided', 
            exact = F, conf.int = T, conf.level = 0.99)
```

Some remarks:
- `exact = F` produces approximate $p$-values and confidence intervals; you may see warning messages if this is excluded
-   pseudo-median is a measure of center, but not the same as a median or mean (check!)

::: callout-note
## Your turn 1

Perform the analogous inference using the $t$ test and compare the results. Do the tests agree at the 1% significance level?

```{r your turn 1, include = F}
# perform t test at 1% level to compare

```
:::

::: {.callout-note collapse="true"}
## Solution
The tests do not agree: the signed rank test rejects at the 1% level, but the $t$ test does not.

```{r your turn 1 solution}
# perform t test at 1% level to compare
t.test(ddt, mu = 3, alternative = 'two.sided', conf.level = 0.99)
```
:::

::: callout-note
## Your turn 2

Perform the signed rank test to determine whether actual weight exceeds desired weight by more than 10lbs at the 5% significance level. Report the result in the usual narrative format. Compare your result with the inference obtained from a $t$ test.

```{r your turn 2, include = F}
# small sample of weight differences
set.seed(51424)
weight.diff <- sample(brfss$weight - brfss$wtdesire, 12)

# assumptions don't hold
hist(weight.diff, breaks = 10)

# use signed rank test to determine whether actual exceeds desired by at least 10lbs at 5% significance level

# check t test result to compare

```
:::

::: {.callout-note collapse="true"}
## Solution

```{r your turn 2 solution}
# use signed rank test to determine whether actual exceeds desired by at least 10lbs
wilcox.test(weight.diff, mu = 10, alternative = 'greater', 
            exact = F, conf.int = T, conf.level = 0.95)

# check t test result to compare
t.test(weight.diff, mu = 10, alternative = 'greater', conf.level = 0.95)
```

Interpretation of the signed rank test test:

> The data provide evidence that actual weight exceeds desired weight by more than 10lbs (signed rank statistic *V* = 61, *p* = 0.0456).

The signed rank test finds evidence that actual weight exceeds desired weight by more than 10lbs, where the $t$ test does not.
:::

### Two-sample inference: rank sum test

The rank-sum test is a nonparametric alternative to the two-sample $t$ test based on ranks. The key idea for the test is that if observations in both groups come from the same population distribution then they should be exchangeable (*i.e.*, groupings don't matter).

Thus, the only assumption for this test is that data are independent. The test can be directional, and thus it is possible to test the following hypotheses comparing centers:

$$
H_0: c_1 = c_2\quad\text{vs}\quad H_A: c_1 \mathrel{\substack{<\\\neq\\>}} c_2
$$

#### The alternative hypothesis

This test is a bit funny in that the null hypothesis is really that *the distributions are exactly the same*. The alternative to this possibility can come about in a number of ways. The alternative is usually interpreted as a *difference in location*, primarily because this is the situation that the test has power to detect. 

So, it is often said that the test also assumes that the samples differ only in location. In other words, the test is most appropriate when the histograms look "shifted", but not fundamentally different, as illustrated below.

```{r, fig.width = 9, fig.height = 2, echo = F}
par(mfrow = c(1, 3),
    mar = c(2, 2, 2, 1),
    cex = 1)
curve(dgamma(x, shape = 2, rate = 1), 
      from = 0, to = 10,
      xaxt = 'n', yaxt = 'n',
      xlab = '', ylab = '')
abline(v = 2, lty = 2)
curve(dgamma(x - 3, shape = 2, rate = 1), 
      from = 3, to = 10,
      xaxt = 'n', yaxt = 'n',
      xlab = '', ylab = '',
      add = T, col = 2)
abline(v = 5, lty = 2, col = 2)
title(ylab = 'frequency', line = 0.5)
title(xlab = 'values', line = 0.5)
title(main = 'assumptions met perfectly')

curve(dgamma(x, shape = 2, rate = 1), 
      from = 0, to = 10,
      xaxt = 'n', yaxt = 'n',
      xlab = '', ylab = '')
abline(v = 2, lty = 2)
curve(dgamma(x - 3, shape = 3, rate = 1), 
      from = 3, to = 10,
      xaxt = 'n', yaxt = 'n',
      xlab = '', ylab = '',
      add = T, col = 2)
abline(v = 6, lty = 2, col = 2)
title(ylab = 'frequency', line = 0.5)
title(xlab = 'values', line = 0.5)
title(main = 'assumptions reasonable')

curve(dgamma(x, shape = 2, rate = 1), 
      from = 0, to = 10,
      xaxt = 'n', yaxt = 'n',
      xlab = '', ylab = '')
abline(v = 2, lty = 2)
curve(dgamma(x, shape = 1, rate = 1/3), 
      from = 0, to = 10,
      xaxt = 'n', yaxt = 'n',
      xlab = '', ylab = '',
      add = T, col = 2)
abline(v = 3, lty = 2, col = 2)
title(ylab = 'frequency', line = 0.5)
title(xlab = 'values', line = 0.5)
title(main = 'assumptions not met')
```

In all of these cases, there is a (true) difference in location, but if shape differs too much, the rank sum test should *not* be used. That said, it can be hard to tell with small samples, so it may not really be practical to to check this assumption.


**Example 1.** Out-of-state tuition costs from 26 public and 26 private universities. These data differ primarily in spread, not location; so the rank-sum test might not work well here. 

```{r, fig.width=4, fig.height=3, echo = F}
Sleuth3::ex0332 %>%
  ggplot(aes(x = OutOfState)) +
  facet_wrap(~Type, nrow = 2, scales = 'free_y') +
  geom_histogram(aes(y = after_stat(density)),
                 alpha = 0.6, binwidth = 5000) +
  stat_density(aes(y = after_stat(density)), 
               bw = 6000, alpha = 0.2) +
  labs(y = '', x = 'tuition') +
  scale_y_continuous(labels = NULL, breaks = NULL) +
  scale_x_continuous(n.breaks = 5, limits = c(0, 50000)) +
  theme_minimal(base_size = 12) +
  theme(panel.grid = element_blank())
```


**Example 2.** Deviations from expected cancer rates in CT in years with high and low sunspot activity. The shape is a bit hard to discern here, but it seems plausible that the distribution for high sunspot years is shifted to the right of that for low sunspot years. So, the rank sum test would be appropriate here.

```{r, fig.width=4, fig.height=3, echo = F}
# load data
cancer <- read_csv('data/cancer.csv')
# cancer <- cancer |> mutate(delta = rate - lag(rate))
cancer %>%
  ggplot(aes(x = delta)) +
  facet_wrap(~sunspot, nrow = 2, scales = 'free_y') +
  geom_histogram(aes(y = after_stat(density)),
                 alpha = 0.6, bins = 8) +
  stat_density(aes(y = after_stat(density)), 
               bw = 0.2, alpha = 0.2) +
  labs(y = '', x = 'change in cancer rate from prior year (per 100K)') +
  scale_y_continuous(labels = NULL, breaks = NULL) +
  scale_x_continuous(n.breaks = 5, limits = c(-0.5, 0.8)) +
  theme_minimal(base_size = 12) +
  theme(panel.grid = element_blank())
```



#### Rank sum test procedure

The rank sum procedure, though a bit opaque, is rather simple:

1.  \[pool\] Combine observations from both groups
2.  \[rank\] Sort and rank pooled observations
3.  \[sum\] Add up ranks in the first group
4.  \[adjust\] Subtract $\frac{n_1(n_1 + 1)}{2}$, where $n_1$ is the sample size of the first group

The test rejects if the sum is larger than expected in the direction of the alternative. As in the signed rank test, combinatorics are used to determine a $p$-value for the test.

The rationale for this procedure is that if the distributions are the same, then the ranks should be evenly distributed among the two groups; this induces a particular sampling distribution on the sum of the ranks in each group. The adjustment facilitates computation of $p$-values.

Let's illustrate using data from an experiment in which participants were randomly assigned to receive a fish oil supplement or a regular oil supplement. For each subject, the reduction in blood pressure was measured after a period of time on the treatments.

```{r fish oil data, fig.width = 4, fig.height = 3}
# load dataset
fish.oil <- Sleuth3::ex0112 |> rename_with(tolower)

# make boxplot
boxplot(bp ~ diet, data = fish.oil, horizontal = T)
```

There's a bit of difference in spread, but enough of a shift in location that the rank sum test is reasonable to apply.

::: callout-tip
## Check your understanding

Carry out the rank sum procedure outlined above and compute the rank sum statistic by summing up the ranks in the fish oil group.

To facilitate calculations, here are the data in order of increasing blood pressure:

```{r rank sum test: check your understanding}
fish.oil |> arrange(bp)
```

Add a column of ranks by hand (or in R if you can figure out how!), averaging ranks for any ties. Then add up the ranks in the `FishOil` group, and subtract $\frac{n_1(n_1 + 1)}{2} = \frac{7\times 8}{2} = 28$ to obtain the rank sum statistic.
:::

::: {.callout-tip collapse="true"}
## Solution

The output below illustrates the rankings and selection of which ones to add up. Don't worry about the codes

```{r rank sum test: check your understanding solution}
# again, ignore the codes; look at output
fish.oil.ranksum <- fish.oil |> 
  mutate(rank = rank(bp),
         ranks.fish = rank*(diet == 'FishOil')) |>
  arrange(bp)
fish.oil.ranksum

# rank sum statistic
n1 <- count(fish.oil, diet)$n[1]
sum(fish.oil.ranksum$ranks.fish) - n1*(n1 + 1)/2
```
:::

#### Implementation using `wilcox.test(...)`

The `wilcox.test` function also implements the rank sum test, using the same syntax as `t.test(...)`. For example, using the fish oil data, we might test at the 1% significance level whether the fish oil supplement caused a greater reduction in blood pressure:


```{r, echo=T}
wilcox.test(bp ~ diet, data = fish.oil, 
            mu = 0, alternative = 'greater', 
            exact = F, conf.int = T, conf.level = 0.99)
```

For this test, the $p$-value gives the percentage of possible rank allocations among the groups for which the rank sum is at least as favorable to $H_A$; again this is computed using combinatorics or approximation methods.

In this instance, the $p$-value indicates that only about 1.96% of all possible rank allocations among the two groups would produce a rank sum statistic at least as large. Thus, testing at the 1% significance level:

> The data provide do not provide sufficient evidence at the 1% significance level that the fish oil supplement caused a greater reduction in blood pressure than the regular oil supplement (rank sum statistic *W* = 41, *p* = 0.01957).

::: callout-note
## Your turn 3

Perform the corresponding $t$ test for comparison at the 1% significance level. Do the tests agree?

```{r your turn 3, include = F}
# t test for effect of treatment at 1% level

```

:::

::: {.callout-note collapse="true"}
## Solution

The tests do not agree; the $t$ test supports evidence of an effect at the 1% level where the rank sum test does not.

```{r your turn 3 solution}
# t test for effect of treatment at 1% level
t.test(bp ~ diet, data = fish.oil, mu = 0, 
       alternative = 'greater', conf.level = 0.95)
```
:::

::: callout-note
## Your turn 4

Use the `cancer` dataset (specifically the `delta` variable) to test whether the change in cancer rate is higher in years with high sunspot activity. Carry out the test at the 5% level, and report the result in the usual narrative style.

```{r your turn 4, include = F}
# test whether change in cancer rate is higher in years with high sunspot activity at the 5% level

```
:::

::: {.callout-note collapse="true"}
## Solution

```{r your turn 4 solution}
# test whether change in cancer rate is higher in years with high sunspot activity at the 5% level
wilcox.test(delta ~ sunspot, data = cancer, mu = 0,
            exact = F, alternative = 'greater', 
            conf.int = T, conf.level = 0.95)
```

Interpretation:

> The data provide no evidence that the change in cancer rate is higher in years with high sunspot activity (rank sum statistic *W* = 157.5, *p* = 0.3072). 

:::

### Practice problem

1. Is there a difference in cholesterol associated with consuming oat bran compared with consuming corn flakes? Use the `cholesterol` dataset to test for a difference at the 5% level using a nonparametric test.

    a. Construct boxplots to compare the distributions for location shift. Does the nonparametric test seem appropriate?
    b. Carry out the test.
    c. Report the test result in the usual narrative style.

```{r practice problem, include = F}
# read in data and preview
cholesterol <- read_csv('data/cholesterol.csv') |> rename_with(tolower)
head(cholesterol)

# part a: make a boxplot and assess whether the nonparametric test is appropriate
boxplot(cholesterol ~ diet, data = cholesterol, horizontal = T)
cholesterol |> count(diet)

# part b: carry out the test
wilcox.test(cholesterol ~ diet, data = cholesterol, mu = 0,
            exact = F, alternative = 'two.sided', conf.int = T,
            conf.level = 0.95)
```