---
title: "Descriptive statistics"
subtitle: "Quantitative and graphical techniques for summarizing data"
format: 
  revealjs:
    logo: img/poly-logo-2.jpg
    footer: "STAT218"
    smaller: true
    mermaid:
      theme: neutral
execute: 
  echo: false
  warning: false
  message: false
---

## Today's agenda

## What are descriptive statistics?

Descriptive statistics provide concise summaries of the observations of one or more variables. They typically focus on:

1.  identifying typical or "central" values
2.  characterizing the variability or "spread" of values
3.  visualizing how observations are distributed among the possible values of the variable(s)

Descriptive techniques can be either quantitative or graphical summaries.

We will start by considering the **frequency distribution**: a graphical or tabular display of how frequently values of the variable were observed.

## Today's example data: FAMuSS

Observational study of 595 individuals comparing change in arm strength before and after resistance training between genotypes for a region of interest on the ACTN3 gene.

> Pescatello, L. S., *et al.* (2013). Highlights from the functional single nucleotide polymorphisms associated with human muscle size and strength or FAMuSS study. BioMed research international, 2013.

```{r}
library(tidyverse)
library(oibiostat)
library(pander)
data(famuss)
head(famuss, 4) %>% pander(caption = 'Example data rows')
```

## Categorical frequency distributions

*For categorical variables, the frequency distribution is simply an observation count by category. For example:*

::: columns
::: {.column width="0.2"}
```{r}
set.seed(11424)
famuss %>% 
  mutate(participant.id = row_number()) %>%
  rename(genotype = actn3.r577x) %>%
  select(participant.id, genotype) %>% 
  sample_n(size = 6) %>% 
  pander(caption = 'Data table')
```
:::

::: {.column width="0.8"}
```{r}
tbl <- famuss %>% 
  mutate(participant = row_number()) %>%
  rename(genotype = actn3.r577x) %>%
  select(genotype) %>%
  table() 

tbl %>%
  pander(caption = 'Frequency distribution')
```

```{r}
famuss %>% 
  mutate(participant = row_number()) %>%
  rename(genotype = actn3.r577x) %>%
  pull(genotype) %>%
  plot(cex.names = 2,
       cex.axis = 2)

```
:::
:::

## Numeric frequency distributions

Frequency distributions of numeric variables are observation counts by *range*.

::: columns
::: {.column width="0.3"}
```{r}
famuss %>%
  mutate(participant.id = row_number()) %>%
  select(participant.id, bmi) %>%
  sample_n(size = 6) %>%
  pander(caption = 'Data table')
```
:::

::: {.column width="0.7"}
```{r}
famuss %>%
  transmute(bmi.range = cut(bmi, breaks = seq(10, 50, by = 10))) %>%
  table() %>%
  pander(caption = 'Frequency distribution')
hist(famuss$bmi, 
     breaks = 3, 
     main = '', 
     xlab = 'BMI',
     ylab = '',
     cex.axis = 2, 
     cex.lab = 2)
```
:::
:::

The operation of dividing a numeric variable into interval ranges is called **binning**.

## Histograms

The graphical display of a frequency distribution for a numeric variable is called a **histogram**. Binning has a big effect on the visual impression.

```{r}
layout(matrix(1:4, nrow = 2, byrow = T))
hist(famuss$bmi, 
     breaks = 4,
     xlab = 'BMI',
     ylab = '',
     main = '4 bins',
     xlim = c(10, 50),
     ylim = c(0, 450),
     cex.axis = 2, 
     cex.lab = 2,
     cex.main = 2)
hist(famuss$bmi, 
     breaks = 6,
     ylim = c(0, 450),
     xlim = c(10, 50),
     xlab = 'BMI',
     ylab = '',
     main = '6 bins',
     cex.axis = 2, 
     cex.lab = 2,
     cex.main = 2)
hist(famuss$bmi, 
     xlim = c(10, 50),
     ylim = c(0, 450),
     breaks = 15,
     xlab = 'BMI',
     ylab = '',
     main = '15 bins',
     cex.axis = 2, 
     cex.lab = 2,
     cex.main = 2)
hist(famuss$bmi, 
     xlim = c(10, 50),
     ylim = c(0, 450),
     breaks = 58,
     xlab = 'BMI',
     ylab = '',
     main = '58 bins',
     cex.axis = 2, 
     cex.lab = 2,
     cex.main = 2)
```

## Shapes

For numeric variables, the histogram reveals the **shape** of the distribution:

-   **symmetric** if it shows left-right symmetry about a central value
-   **skewed** if it stretches farther in one direction from a central value

```{r, fig.height=3}
par(mfrow = c(1, 3))
curve(dgamma(abs(10 - x), shape = 3, scale = 1), from = 0, to = 10,
      xlab = '', ylab = '', main = 'left skew', cex.main = 3, 
      xaxt = 'n', yaxt = 'n')
curve(dnorm, from = -3, to = 3,
      xlab = '', ylab = '', main = 'symmetric', cex.main = 3,
      xaxt = 'n', yaxt = 'n')
curve(dgamma(x, shape = 3, scale = 1), from = 0, to = 10,
      xlab = '', ylab = '', main = 'right skew', cex.main = 3, 
      xaxt = 'n', yaxt = 'n')
```

## Modes

Histograms also reveal the number of **modes** or local peaks of frequency distributions.

-   **uniform** if there are zero peaks
-   **unimodal** if there is one peak
-   **bimodal** if there are two peaks
-   **multimodal** if there are two or more peaks

```{r, fig.height=3}
par(mfrow = c(1, 4))

curve(dunif, from = -1, to = 2,
      xlab = '', ylab = '', main = 'uniform', cex.main = 3, 
      xaxt = 'n', yaxt = 'n')
curve(0.4*dnorm(x, mean = 0) + 0.6*dnorm(x, mean = 2), from = -3, to = 6,
      xlab = '', ylab = '', main = 'unimodal', cex.main = 3,
      xaxt = 'n', yaxt = 'n')
curve(0.4*dnorm(x, mean = -2) + 0.6*dnorm(x, mean = 2), from = -5, to = 5,
      xlab = '', ylab = '', main = 'bimodal', cex.main = 3, 
      xaxt = 'n', yaxt = 'n')
curve(0.2*dnorm(x, mean = -2) + 0.5*dnorm(x, mean = 2) + 0.3*dnorm(x, mean = 6), from = -5, to = 10,
      xlab = '', ylab = '', main = 'multimodal', cex.main = 3, 
      xaxt = 'n', yaxt = 'n')
```

## Your turn: characterizing shapes

```{r}
par(mfrow = c(2, 2))
hist(famuss$height, main = 'Heights in FAMuSS study', xlab = 'Height')
hist(famuss$weight, main = 'Weights in FAMuSS study', xlab = 'Weight')
hist(famuss$age, main = 'Ages in FAMuSS study', xlab = 'Age')
hist(famuss$bmi, main = 'BMI in FAMuSS study', xlab = 'BMI')
```

## More shapes

```{r}
par(mfrow = c(2, 2))
set.seed(11524)
runif(1000, min = -5, max = 2) %>% hist(main = '', xlab = 'x')
-rpois(1000, lambda = 2) %>% hist(main = '', xlab = 'x', breaks = 6)
c(rnorm(400, mean = -4, sd = 2), rnorm(600, mean = 8, sd = 5)) %>%
  hist(main = '', xlab = 'x', breaks = 20)
c(rexp(500, rate = 1), 10 - rexp(600, rate = 2))  %>%
  hist(main = '', xlab = 'x', breaks = 20)
```


## Descriptive measures

Frequency distributions (especially graphics) are great for many purposes but they have limitations:

-   minimal "data reduction", especially for many bins/categories
-   sensitive to choice of binning
-   interpretation is subjective

By contrast, descriptive measures reduce all observations of a variable down to just one number. There are two common types of measures:

-   **measures of center**: mean, median, mode
-   **measures of spread**: absolute deviation, standard deviation, interquartile range, range

## Measures of center

A measure of center is a statistic that reflects the typical value of one or more variables.

::: columns
::: {.column width="0.5"}
There are three common measures of center, each of which corresponds to a slightly different meaning of "typical":

| Measure | Definition          |
|---------|---------------------|
| Mode    | Most frequent value |
| Mean    | Average value       |
| Median  | Middle value        |
:::

::: {.column width="0.5"}
Suppose your data consisted of the following observations of age in years:

```{r}
c(19, 19, 21, 25, 31) %>% pander()
```

-   the **mode** or most frequent value is 19
-   the **median** or middle value is 21
-   the **mean** or average value is $\frac{19 + 19 + 21 + 25 + 31}{5}$ = 23
:::
:::

*These measures are only used with numeric variables.* Other clarifications:

-   for continuous variables, mode will be computed subject to binning
-   for an even number of observations, the median is defined as the midpoint between the two middle values

## Comparing measures of center

Each statistic is a little different, but often they roughly agree; for example, all are between 20 and 25, which seems to capture the typical age.

```{r, fig.width = 10, fig.height = 4}
makehist <- function(x, b, t, xlab, leg, nmodes){
h <- hist(x, main = b, breaks = t, xlab = xlab)
abline(v = mean(x), col = 2, lty = 2)
abline(v = median(x), col = 4, lty = 3)
abline(v = h$mids[which(h$counts %in% sort(h$counts, decreasing = T)[1:nmodes])], col = 6, lty = 4)
if(leg){
legend(quantile(h$mids, 0.7), max(h$counts), legend = c("Mean", "Median", "Mode"), col = c(2, 4, 6), lty = c(2, 3, 4))
}
}

makehist(famuss$bmi, '', 15, 'BMI', T, 1)
```

*When might one measure might be a better choice than the others? Can you think of an example?*

<!-- ## When to use what -->

<!-- Usually either mean or median are used, unless extreme skewness or multiple modes are present. -->

<!-- ```{r, fig.width = 12, fig.height = 4} -->

<!-- set.seed(11524) -->

<!-- x_skew <- c(rgamma(n = 1000, shape = 4, rate = 1/10),  -->

<!--             runif(n = 500, min = 70, max = 300)) -->

<!-- x_bi <- c(rnorm(1000, mean = -3), -->

<!--           rnorm(1000, mean = 3)) -->

<!-- par(mfrow = c(1, 2)) -->

<!-- makehist(x_skew, '', 20, '', T, 1) -->

<!-- makehist(x_bi, '', 20, '', F, 2) -->

<!-- ``` -->

## Percentiles

The median is an example of a **percentile**: a value with specified proportions of data lying both above and below. For example, the 20th percentile is the value with 20% of observations below and 80% of observations above.

*Ranking* observations helps to find this number. Suppose we have 5 observations:

```{r}
x <- c(19, 20, 21, 25, 31)
rbind(age = x, rank=rank(x)) %>% pander()
```

The 20th percentile is 20 since it is ranked second when observations are listed in order:

-   20% below (19, 20)
-   80% above (20, 21, 25, 31)

> Software implementations have a variety of ways for calculating percentiles when an exact solution isn't available due to ties (repeated values) or sample size.

## Cumulative frequency distribution

Closely related to the concept of a percentile is the *cumulative frequency distribution*: the proportion of observations smaller than or equal to each unique observed value.

::: columns
::: {.column width="0.6"}
```{r, fig.height = 5, fig.width = 5, fig.align='center'}
famuss$age[famuss$age < 30] %>%
  # sample(size = 50) %>%
  ecdf() %>% 
  plot(main = '', 
       xlab = 'age', 
       ylab = 'cumulative frequency',
       cex.lab = 1.5,
       cex.axis = 1.5)
```
:::

::: {.column width="0.4"}
Interpretation of some specific values:

-   about 40% of the subjects are 20 or younger
-   about 80% of the subjects are 24 or younger

*Your turn*:

1.  Roughly what percentage of subjects are 22 or younger?
2.  About what age is the 10th percentile?
:::
:::

## Measures of spread

The *spread* of observations refers to how concentrated or diffuse the values are.

```{r, fig.width = 8, fig.height = 2.5, fig.align='center'}
par(mfrow = c(1, 2))
curve(dnorm, from = -3, to = 3, 
      main = 'more spread', 
      xaxt = 'n', 
      yaxt = 'n',
      xlab = '',
      ylab = '')
curve(dnorm(x, sd = 0.25), from = -3, to = 3, 
      main = 'less spread', 
      xaxt = 'n', 
      yaxt = 'n',
      xlab = '',
      ylab = '')
```

Two ways to understand and measure spread:

-   *ranges* of values capturing much of the distribution
-   *deviations* of values from a central value

## Range measures

A simple way to understand and measure spread is based on ranges. Consider more ages, sorted and ranked:

```{r}
x <- c(16, 18, 19, 20, 21, 22, 25, 26, 28, 29, 30, 34)
rbind(age = x, rank = rank(x)) %>% pander()
```

-   The **range** is the difference \[maximum value\] - \[minimum value\] $$\text{range} = 34 - 16 = 18$$

-   The **interquartile range** (IQR) is the difference \[75th percentile\] - \[25th percentile\] $$\text{IQR} = 29 - 19 = 10$$ *When might you prefer IQR to range? Can you think of an example?*

## Deviation measures

Another way is based on *deviations* from a central value. Continuing the example, the mean age is is 24. The deviations of each observation from the mean are:

```{r}
x <- c(16, 18, 19, 20, 21, 22, 25, 26, 28, 29, 30, 34)

rbind(age = x, deviation = x - mean(x)) %>% pander()
```

The **average deviation** is defined as the average of the absolute values of the deviations from the mean: $$
\frac{8 + 6 + 5 + 4 + 3 + 2 + 1 + 2 + 4 + 5 + 6}{12}
$$ The **standard deviation** is defined in terms of the squared deviations from the mean: $$
\sqrt{\frac{(-8)^2 + (-6)^2 + (-5)^2 + (-4)^2 + (-3)^2 + (-2)^2 + (1)^2 + (2)^2 + (4)^2 + (5)^2 + (6)^2}{12 - 1}}
$$

## Calculations

Listed from largest to smallest, here are each of the measures of spread for the 12 ages:

```{r}
c(range = diff(range(x)),
  iqr = IQR(x),
  st.dev = sd(x),
  avg.dev = mean(abs(x - mean(x)))) %>%
  pander()
```

They are not always ordered in this way; in lab you'll explore further examples.

> While it's good to know how to reconstruct these calculations, you won't actually have to perform them from scratch in practice, so it's more important that you understand their conceptual basis

## Numerical summaries

Two sets of descriptive statistics are typically reported to give numerical summaries of data.

::: columns
::: {.column width="0.5"}
The *five-number summary* is a collection of five percentiles that succinctly describe the distribution of observed values of a variable:

| Statistic name     | Meaning          |
|--------------------|------------------|
| **minimum**        | 0th percentile   |
| **first quartile** | 25th percentile  |
| **median**         | 50th percentile  |
| **third quartile** | 75th percentile  |
| **maximum**        | 100th percentile |
:::

::: {.column width="0.5"}
In addition, the *mean and standard deviation* are often reported.

| Statistic name         | Meaning               |
|------------------------|-----------------------|
| **Mean**               | average value         |
| **Standard deviation** | dispersion about mean |
:::
:::

## Boxplots

Boxplots provide a graphical display of the five-number summary, plus the standard deviation.

::: columns
::: {.column width="40%"}
![](img/boxplot-anatomy.png)
:::
::: {.column width="60%"}
The basic anatomy is:

- box shows quartiles
- whiskers are multiples of the standard deviation (usually 1.5)
- observations outside the whiskers are plotted separately

The main advantage this has over a histogram is that it's much more compact.
:::
:::

## Example descriptive summary

Suppose we wanted to use our descriptive tools to compare the change in dominant arm strength with the change in nondominant arm strength in the FAMuSS (sports gene) study.

::: columns
::: {.column width="50%"}
```{r, fig.width=5, fig.height=4}
layout(matrix(1:2, nrow = 2), height = c(3, 2))
par(mar=c(5.1, 4.1, 1.1, 2.1))
hist(famuss$ndrm.ch, main = 'nondominant arm', xlab = 'change')
boxplot(famuss$ndrm.ch, range = 3, horizontal = T)
# summary(famuss$ndrm.ch) %>% pander()
```

:::

::: {.column width="50%"}
```{r, fig.width=5, fig.height=4}
layout(matrix(1:2, nrow = 2), height = c(3, 2))
par(mar=c(5.1, 4.1, 1.1, 2.1))
hist(famuss$drm.ch, main = 'dominant arm', xlab = 'change')
boxplot(famuss$drm.ch, range = 3, horizontal = T)
# summary(famuss$drm.ch) %>% pander()
```
:::
:::

*What are the shapes? How many modes? Differences in center? Differences in spread?*

## Lab: robustness

For this lab we'll continue to work with the FAMuSS data as we have throughout lecture.

This lab has two objectives:

1.  Teach you to compute descriptive statistics and prepare graphical summaries for a single variable in R
2.  Allow you to explore the concept of robustness and learn when and why to use certain descriptive statistics in place of others

# Extras

## Formulae

The general formulae for the deviation measures are expressed as follows. 

Denote $n$ observations of a variable $x$ by $x_1, \dots, x_n$, so that $x_i$ indicates the value of the $i$th observation. 

The **mean** of the observations is denoted by $\bar{x}$ and defined as:
$$
\bar{x} = \frac{1}{n}\sum_i x_i
$$

Then, the **average deviation** is: $$
\text{average deviation} = \frac{1}{n}\sum_i |x_i - \bar{x}|
$$ The **standard deviation** is: $$
\text{standard deviation} = \sqrt{\frac{1}{n - 1}\sum_i (x_i - \bar{x})^2}
$$
