---
title: "Chapter 8: Comparing a Numerical Variable Across More Than Two Groups"
format: 
  html:
    toc: true
  pdf:
    keep-tex: false
    include-in-header:
      text: |
          \usepackage{fancyhdr}
          \pagestyle{fancy}
          \fancyhf{}
          \fancyhead[R]{Chapter 8: Comparing a Numerical Variable Across More Than Two Groups}
          \fancyfoot[C]{\thepage}
  docx:
    toc: false
prefer-html: true
embed-resources: true
bibliography: references.bib
reference-location: section
execute:
  echo: false
  message: false
  warning: false
---

```{r}
library(tidyverse)
library(mosaic)
library(infer)
library(broom)
```

In the previous chapter, we covered how we could compare a numerical variable across two groups using (1) a difference in two means (independent samples), and (2) the mean of the differences (paired). 

## ANOVA (ANalysis Of VAriance) 

In this chapter, we will learn how to compare a numerical variable across more than two groups using a statistical analysis called ANOVA.

### Example 8.1: IMDb Scores between Genres

Recall the IMDb Scores for movies released in 2020 from Chapter 5. The data set is comprised of the following variables collected on each movie:

| **Variable**     | **Description**                                             |
|------------------|-------------------------------------------------------------|
| `Movie`          | Title of the movie                                          |
| `Rating`         | Average IMDb user rating score from 1 to 10                 |
| `numVotes`       | Number of votes from IMDb users                             |
| `Genre`          | Categories the movie falls into (e.g., Action, Drama, etc.) |
| `2020 Gross`     | Gross profit from movie viewing                             |
| `runtimeMinutes` | Length of movie (in minutes)                                |
|                  |                                                             |

```{r data-cleaning}
#| include: false

movies <- readxl::read_xlsx("data/movies_2020.xlsx") |>  
  distinct(Movie, .keep_all = TRUE)

title_ids <- read_csv("data/movie_ids.csv")
  
movie_ids <- left_join(movies, 
                       title_ids, 
                       by = 
                         intersect(
                           colnames(movies), 
                           colnames(title_ids)
                           )
                       )

ratings <- read_csv("data/ratings.csv")

movie_ratings <- left_join(movie_ids, 
                           ratings, 
                           by = "id"
                           ) |> 
  select(Movie, 
         Genre, 
         `2020 Gross`, 
         runtimeMinutes, 
         averageRating, 
         numVotes) |> 
  drop_na(averageRating) |> 
  rename(Rating = averageRating)
```

Below is a table summarizing the number of observations (movies) in the data set for the five most common Genres.

```{r genre-table}
#| echo: false

movie_ratings |> 
  count(Genre) |> 
  arrange(-n) |> 
  filter(Genre %in% c("Comedy",
                           "Documentary",
                           "Drama",
                           "Thriller/Suspense",
                      "Horror"))
```
**Research Question:** Is there a difference in mean IMDb scores between movie genres?

```{r data-filtering}

genres <- tibble(Genre = c("Comedy", 
                           "Documentary", 
                           "Drama", 
                           "Thriller/Suspense",
                           "Horror")
                 )

movie_ratings <- movie_ratings |> 
  semi_join(genres, by = "Genre") |> 
  mutate(Genre = fct_reorder(Genre, Rating))
```

The output below shows example observations from the data set.

```{r}
#| echo: true
head(movie_ratings, n = 10)
```

1. What is the observational unit for this study?

\vspace{0.6in}

2. What are the variables assessed in this study? What are their roles (explanatory / response) and data types?

\vspace{1in}

3. What are the parameters of interest for this study?

\vspace{2.5in}


4. Think back to last week, what were two ways we visualized one numerical variable and one categorical variable?

\vspace{0.4in}


The figures below display the IMDb Scores across the five movie genre categories.

```{r}
#| fig-width: 4
#| fig-height: 9
#| fig-align: center
#| fig-pos: "H"

ggplot(data = movie_ratings, 
             mapping = aes(x = Rating)) + 
  geom_histogram(binwidth = 1, color = "white") + 
  facet_wrap(~ Genre, ncol = 1, scales = "free_y") +
  theme_bw() +
  theme(aspect.ratio = 0.3) +
  labs(y = "Number of Movies", 
       x = "IMDb Score"
       ) +
  scale_x_continuous(limits = c(0,10), breaks = seq(0,10,2))
```

```{r}
#| fig-pos: "H"
#| fig-align: center

ggplot(data = movie_ratings, 
             mapping = aes(x = Rating, y = Genre)) + 
  geom_boxplot() + 
  theme_bw() +
  labs(y = "Genre of Movie", 
       x = "IMDb Score"
       ) +
  scale_x_continuous(limits = c(0,10), breaks = seq(0,10,2))
```

Answer the following questions about the distributions of IMDb Scores across the five Genres shown above.

5.  Which genre has the highest center?

\vspace{0.25in}

6.  Which genre has the largest spread?

\vspace{0.25in}

7.  Which genre has the most skewed distribution?

\vspace{.25in}

Let's obtain a more complete picture of how different these groups are with summary statistics. Our familiar friend `favstats()` can help us compare summary statistics across different genre groups.

Like before, the rating of the film is the response and the genre is the explanatory variable.

\newpage

```{r stat-comparison}
#| echo: true
favstats(Rating ~ Genre, data = movie_ratings)
```

\vspace{0.2in}

8.  Report the observed mean rating for each genre. Use appropriate notation.

\vspace{1.2in}

9.  Which genres have the largest difference in their mean rating?

\vspace{0.8in}

10.  Which genre has the largest standard deviation in ratings?

\vspace{0.25in}

11.  Which genre has the smallest standard deviation in ratings?

\vspace{0.25in}

12.  How many times larger is your answer in #6 than your answer in #7?

\vspace{0.5in}

\newpage

Now that we have explored our data with summary statistics and visualizations, we want to use our data to draw inferences and make claims about the larger population (all movies).

14. Set up the null and alternative hypotheses.

+ In words:

\vspace{1.5in}

+ In symbols:

\vspace{1.5in}

In order to test our research question, we could conduct a simulation similar to what we did with two categorical variables (yawn experiment) and discussed when comparing a numerical variable across two groups.

+ Step 1: Write the ____________ and ____________ on ______ cards.

\vspace{0.1in}

+ Step 2: Simulate what could have happened if the null was true and ________________.

\vspace{0.1in}

+ Step 3: Generate a new data set by _________________________________.

\vspace{0.1in}

+ Step 4: Calculate the _____________________________ for the new simulated data set and add it to the dot plot.

\vspace{0.1in}

We would then repeat this process 100 or 1000 times to get an idea of what the sampling distribution of the *test statistic* looks like.

::: callout-note
### Introducing a new *test statistic*

In an ANOVA, there are more than two groups that we wish to compare how different the means are from each other. We could make every comparison of two means (Drama - Action, Horror - Documentary, Comedy - Adventure, etc.), but how would we use these numbers to summarize how different **all** of the groups are from each other?

Enter the F-statistic! An F-statistic summarizes two quantities:

-   How different the means of the groups are from each other
-   How different the observations in each group are from the mean of their group

:::

To me, an F-statistic makes more sense if I visualize what these pieces mean. In the plot below, I've added three pieces,

-   Orange individual points within each group (these are the movies)
-   A black dashed line across the entire plot
-   A blue solid line across each genre group

```{r anova-ss-viz}
#| fig-pos: "H"
#| fig-width: 8
#| fig-height: 5
#| fig-align: center

overall_mean <- movie_ratings |> 
  summarize(mean(Rating)) |> 
  pull()

group_means <- movie_ratings |> 
  group_by(Genre) |> 
  summarize(mean(Rating)) |> 
  pull()

movie_ratings |> 
  ggplot(mapping = aes(y = Genre, 
                       x = Rating,
                       shape = Genre)
         ) + 
  geom_boxplot(alpha = 0.1, width = 0.7, fill = "gray", color = "gray") + 
  geom_jitter(width = 0.05, alpha = 0.8, color = "orange3") +
  geom_vline(xintercept = overall_mean, 
             color = "black", 
             linetype = "dashed", 
             lwd = 1) +
  geom_segment(y = 0.5, yend = 1.5, x = group_means[1], xend = group_means[1],
               color = "steelblue", lwd = 1, linetype = "solid") +
  geom_segment(y = 1.5, yend = 2.5, x = group_means[2], xend = group_means[2],
               color = "steelblue", lwd = 1, linetype = "solid") +
  geom_segment(y = 2.5, yend = 3.5, x = group_means[3], xend = group_means[3],
               color = "steelblue", lwd = 1, linetype = "solid") +
  geom_segment(y = 3.5, yend = 4.5, x = group_means[4], xend = group_means[4],
               color = "steelblue", lwd = 1, linetype = "solid") +
  geom_segment(y = 4.5, yend = 5.5, x = group_means[5], xend = group_means[5],
               color = "steelblue", lwd = 1, linetype = "solid") +
  geom_segment(y = 5.5, yend = 6.5, x = group_means[6], xend = group_means[6],
               color = "steelblue", lwd = 1, linetype = "solid") +
  geom_segment(y = 6.5, yend = 7.5, x = group_means[7], xend = group_means[7],
               color = "steelblue", lwd = 1, linetype = "solid") +
  theme_bw() +
  theme(legend.position = "none", 
        axis.title = element_text(size = 16), 
        axis.text.x = element_text(size = 14)
        ) +
  labs(y = "Movie Genre", 
       x = "IMDb Score") +
  scale_x_continuous(limits = c(0,10))
```

15. What does the black dashed line across the entire plot represent?

\vspace{0.5in}

16. What do the solid blue lines across each group's boxplot represent? *Hint: The solid blue line is different from the gray solid lines.*

\vspace{0.5in}

::: callout-note
### Components of an F-statistic

The two components of an F-statistic are called the *sum of squares between groups* (SSG) and the *sum of squares of the errors* (SSE). Let's break down what each of these mean.

\vspace{0.1in}

The **SSG** compares each group's mean to the overall mean. As its name indicates, these differences are then **squared** and added together.

```{r}
#| out-width: 70%
#| fig-align: center
knitr::include_graphics("08-images/ssg.png")
```

The **SSE** measures how far an observation is from the mean of that group. As its name indicates, these differences are **squared** and then added together.

\vspace{0.1in}

```{r}
#| out-width: 70%
#| fig-align: center
knitr::include_graphics("08-images/sse.png")
```

There is one final part to an F-statistic. We take each of these quantities (SSG, SSE) and divide them by their respective degrees of freedom. The degrees of freedom are calculated based on (1) the number of items available and (2) the number of statistics that need to be calculated.

\vspace{0.1in}

For the SSG, we have $k$ groups and we need to calculate the overall mean. So, our resulting degrees of freedom are $k - 1$.

\vspace{0.1in}

For the SSE, we have $n$ observations and we need to calculate $k$ group means. So, our resulting degrees of freedom are $n - k$.

\vspace{0.1in}

Now, putting all of these pieces together, we can obtain the magical F-statistic using the following formula:

$$\frac{\frac{SSG}{k-1}}{\frac{SSE}{n-k}} = \frac{MSG}{MSE}$$

```{r}
#| out-width: 100%
#| fig-align: center
knitr::include_graphics("08-images/F-stat.png")
```

:::

17. Draw horizontal lines on the plot above, indicating which values are being compared when calculating the SSG.

\vspace{0.25in}

18. Draw horizontal lines on the plot above, indicating which values are being compared with calculating the SSE.

\vspace{0.25in}

19. How many degrees of freedom does the `Genre` variable (MSG) have?

\vspace{0.5in}

20. How many degrees of freedom does the SSE for our content rating analysis have?

\vspace{0.5in}

21. Can an F-statistic be negative?

\vspace{0.5in}

Let's use simulation to get an idea of the shape of the F-distribution.

```{r}
#| fig-height: 8
#| fig-width: 8
library(nullabor)
set.seed(56156)
lineup_data <- lineup(null_permute("Genre"), movie_ratings, pos = 3) 

lineup_data |> 
ggplot(mapping = aes(x = Rating, 
                     y = Genre)) +
  geom_boxplot() +
  labs(title = "Simulate Data under assumption all IMDb Scores are the same across Genres",
       subtitle = "19 simulated data sets + 1 observed data set from study",
       x = "IMDb Score", 
       y = "Genre") +
  theme(aspect.ratio = 1) +
  theme_bw() +
  facet_wrap(~ .sample)
```

22. Which panel contains the actual data observed in the study? Was it hard to pick out? Remember what it was like trying to pick this out.

\vspace{1.2in}

We could take these and calculate the F-statistic for each panel (simulated data set) and plot this to begin creating the distribution to compare our observed test statistic to. Note, we will see how to use `R` to calculate the F-statistic in just a bit.

```{r}
#| fig-height: 8
#| fig-width: 8

myaov <- function(data) {
  output <- aov(Rating ~ Genre, data = data)
  stat <- output |> tidy() |> slice(1) |> pull(statistic)
  return(stat)
}

fstats <- lineup_data |> 
  select(.sample, Genre, Rating) |> 
  nest(data = c(Genre, Rating)) |>
  mutate(stat = map(data, myaov)) |>
  unnest(stat) |> 
  mutate(F_stat = paste0("F=", round(stat, 2))) |> 
  mutate(plot_type = ifelse(.sample == 3, "target", "null"))

lineup_data |> 
ggplot(mapping = aes(x = Rating, 
                     y = Genre)) +
  geom_boxplot() +
  labs(title = "Simulate Data under assumption all IMDb Scores are the same across Genres",
       subtitle = "19 simulated data sets + 1 observed data set from study",
       x = "IMDb Score", 
       y = "Genre") +
  theme(aspect.ratio = 1) +
  theme_bw() +
  facet_wrap(~ .sample) +
  geom_label(data = fstats, aes(label = F_stat, x = 5, y = 2.5, fill = plot_type), size = 3, color = "white", fontface = "bold", show.legend = F) +
  scale_fill_manual(values = c("gray", "orange3"))
```

```{r}
set.seed(56156)
fstats1000 <- lineup(null_permute("Rating"), movie_ratings, pos = 1, n = 1001)  |> 
  select(.sample, Genre, Rating) |> 
  nest(data = c(Genre, Rating)) |>
  mutate(stat = map(data, myaov)) |>
  unnest(stat) |> 
  mutate(plot_type = ifelse(.sample == 1, "target", "null"))

fstats1000 |> 
  filter(plot_type == "null") |> 
  ggplot(aes(x = stat)) +
  geom_dotplot(method = "histodot",
               dotsize = 0.13,
               ) +
  theme_test() +
  labs(title = "Distribution for F-Statistic (under assumption no difference)",
       y = "",
       x = "Simulated F-statistic") +
  theme(axis.text.y = element_blank(),
        axis.ticks.y = element_blank())
```

23. Take note that our observed F-statistic is 0.97, do you believe this F-statistic is likely to occur under the condition that all mean IMDb movie ratings are the same across all five genres (i.e., the null is true)?

\vspace{0.6in}

Calculating the F-statistic by hand would be terrible! Instead, we will use `R`. The `aov()` function in `R` stands for **a**nalysis **o**f **v**ariance.

```{r aov-code}
#| echo: true
genre_anova <- aov(Rating ~ Genre, # <1>
    data = movie_ratings # <2>
    ) 

genre_anova |> 
  tidy() # <3>
```
1. Save the model in an object called `genre_anova`. Provide the `aov` function a "formula" similar to `favstats()` with: `response` ~ `explanatory`.
2. Tell `aov` what data set to use.
3. Have R output the information from the `genre_anova` object in a nice clean (`tidy`) table for you.

\vspace{0.25in}

22. What is the sum of squares for `Genre` (SSG)?

\vspace{0.25in}

23. What is the sum of squares for the errors (SSE)?

\vspace{0.25in}

24. How was the mean squares for `Genre` (MSG) found?

\vspace{0.25in}

25. How was the mean squares for the errors (MSE) found?

\vspace{0.25in}

26. What is the resulting F-statistic?

\vspace{0.25in}

27. Based on the p-value associated with the F-statistic outputed above, write the conclusion in context of the problem.

\vspace{1.5in}

::: callout-note
### Conditions for using ANOVA (F-statistic)

1. Independent observations *within* groups.
2. Independent observations *between* groups.
3. Equal variance across every group.
4. Either, all sample sizes are sufficiently large, or it reasonable to assume that the populations for each group are normally distributed.

:::

28. Check the conditions for using ANOVA to test whether the mean IMDb score differs between genres.

\vspace{2in}

Alright, so we just learned about how we can analyze the differences in **many** means using ANOVA. As a refresher, with an ANOVA, we're comparing the variability *within* groups (MSE) to the variability *between* groups (MSG).

If we believe that the mean of at least one group is different from the others, ideally in a visualization we'd like to see:

-   large differences in the means **between** the groups
-   small amounts of variability **within** each group

29.  Sketch an example of three box plots that exhibit the characteristics above.

\vspace{2in}

30.  Overall, do you believe any of the genres stand out as really different from the others? Recall how easy or difficult it was to pick out the data plot from all the simulated panels above.

\vspace{1in}

::: callout-note
### Hypothesis Testing Errors

In a hypothesis test, there are two competing hypotheses: the null and the alternative. We make a statement about which one might be true, but we might choose incorrectly. There are four possible scenarios in a hypothesis test:

|                                    | $H_0$ is True  | $H_0$ is False |
|------------------------------------|----------------|----------------|
| Reject $H_0$ (evidence)            | Type I Error   | Good Decision! |
| Fail to Reject $H_0$ (insufficient evidence) | Good Decision! | Type II Error  |

:::

31. Based on the decision you reached from the ANOVA test, what type of error could you have made?

\vspace{0.25in}

32. With an $\alpha = 0.05$, what percent of the time would we expect to make a Type I error?

\vspace{0.25in}

33. How does $\alpha$ relate to the probability of making a Type II error?

\vspace{0.5in}

### Inference after ANOVA

If we had found a "significant" p-value, we could have concluded that at least one of the genres had a different mean movie rating. However, an ANOVA **does not** tell us which group(s) is(are) driving the differences.

What we could do is compare all possible combinations of two means. With five groups, that would result in 10 different hypothesis tests for a difference in means. For example:

+ $\mu_{\text{Comedy}} - \mu_{\text{Documentary}}$,
+ $\mu_{\text{Comedy}} - \mu_{\text{Drama}}$, 
+ $\mu_{\text{Horror}} - \mu_{\text{Thriller}}$,
+ etc.

However, for each hypothesis test we do at an $\alpha$ of 0.05, we risk making a Type I error 5\% of the time. In fact, we can make a mathematical equation for the probability of making a Type I Error, based on the number of tests we perform.

\vspace{0.25cm}

$$
\text{Probability of Making a Type I Error} = 1 - \text{Probability of Not Making a Type I Error}
$$ 

\vspace{-0.2cm} 

$$
\text{Probability of Making a Type I Error} = 1 - (0.95)^{\text{\# of tests}}
$$ 

\vspace{0.2cm}

34. If we do 10 hypothesis tests (think of 10 pairwise comparisons between Genres), what is the probability of us making a Type I Error?

\vspace{0.5in}

::: callout-note
### Bonferonni Correction for Post-Hoc Comparisons

One solution to the problem of multiple comparisons is called the Bonferroni correction. Essentially, you take your $\alpha$ threshold and divide it by the number of tests you are going to perform. 

$$\alpha^*=\frac{\alpha}{\text{number of pairwise comparisons}}$$

You then use this $\alpha^*$ value as the new threshold value for **every** pairwise comparison. If a comparison's p-value is less than $\alpha^*$, then you reject $H_0$ (evidence to support the alternative). If a comparison's p-value is greater than $\alpha^*$, then you fail to reject $H_0$ (insufficient evidence to support the alternative).
:::

35. If our original $\alpha$ was 0.05, what value should we use for $\alpha^*$ with 10 pairwise comparisons?

\vspace{0.5in}

\newpage

Below is a table of all 10 of the pairwise comparisons (hypothesis tests) we could do when comparing the means of two genres.

```{r post-hoc}
#| echo: true
library(emmeans)
emmeans(object = genre_anova,
        specs = ~ Genre
        ) |> 
  pairs(adjust = "none")
```

36. Using the $\alpha^*$ you found above, circle the hypothesis tests whose p-values are less than $\alpha^*$.

Your $\alpha^*$ value should be much less than your original $\alpha$ of 0.05, which makes it **harder** to find evidence to support the alternative (reject the null).

\vspace{0.25in}

\newpage

Alternatively, we can ask R to do this adjustment for us by using `adjust = "bonf"` and then use our standard cut-offs.

```{r}
#| echo: true
emmeans(object = genre_anova,
        specs = ~ Genre
        ) |> 
  pairs(adjust = "bonf")
```
Note there are multiple methods for conducting multiplicity adjustments to control your Type I error rates including `tukey`, `dunnet`, and more!