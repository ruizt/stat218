{
  "hash": "7f9113e8723b60352b8a278e6e5d7bc3",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Introduction to inference\"\nsubtitle: \"Relating population statistics to sample statistics\"\nformat: \n  revealjs:\n    logo: img/poly-logo-2.jpg\n    footer: \"STAT218\"\n    smaller: true\n    mermaid:\n      theme: neutral\nexecute: \n  echo: false\n  warning: false\n  message: false\n---\n\n::: {.cell}\n\n:::\n\n\n## Today's agenda\n\n1. Test 1 discussion\n2. [lecture] Inference vs. description, point estimation, interval estimation\n3. [lab] Exploring interval coverage\n\n## Description vs. inference\n\n> **Statistical inferences** are statements about population statistics based on samples. \n\nTo appreciate the meaning of this, consider the contrast with descriptive findings, which are statements about sample statistics:\n\n::: columns\n::: {.column width=\"50%\"}\n\n::: {.cell}\n::: {.cell-output-display}\n![](week4-inference_files/figure-revealjs/unnamed-chunk-2-1.png){width=480}\n:::\n:::\n\n:::\n\n::: {.column width=\"50%\"}\nMedian percent change by genotype:\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n------------------\n  CC     CT    TT \n------ ------ ----\n 42.9   45.5   50 \n------------------\n\n\n:::\n:::\n\n\nA descriptive finding is:\n\n*Subjects with genotype TT exhibited the largest median percent change in strength*\n:::\n:::\n\nThe corresponding inference would be:\n\n*The median percent change in strength is highest among adults with genotype TT.*\n\n## Inference or description?\n\nSee if you can tell the difference:\n\n1. The proportion of children who developed a peanut allergy was 0.133 in the avoidance group.\n2. The proportion of children who develop peanut allergies is estimated to be 0.133 when peanut protein is avoided in infancy.\n3. The average lifetime of mice on normal 85kCal diets is estimated to be 32.7 months.\n4. The 57 mice on the normal 85kCal diet lived 32.7 months on average.\n5. The relative risk of a CHD event in the high trait anger group compared with the low trait anger group was 2.5.\n6. The relative risk of a CHD event among adults with high trait anger compared with adults with low trait anger is estimated to be 2.5.\n\n## Random sampling\n\n> Sampling establishes the link (or lack thereof) between a sample and a population.\n\n::: columns\n::: {.column width=\"50%\"}\n![](img/srs.png)\n:::\n\n::: {.column width=\"50%\"}\nIn a **simple random sample**, units are chosen in such a way that every individual in the population has an equal probability of inclusion. For the SRS:\n\n- sample statistics mirror population statistics (sample is *representative*)\n- sampling variability depends only on population variability and sample size\n\n:::\n:::\n\n\n## Population models\n\n> Inference consists in using statistics of a random sample to ascertain population statistics under a population model.\n\nA population model represents the distribution of values you'd see if you measured every individual in the study population. We think of the sample values as a random draw.\n\n::: columns\n::: {.column width=\"50%\"}\n\n::: {.cell}\n::: {.cell-output-display}\n![](week4-inference_files/figure-revealjs/unnamed-chunk-4-1.png){width=480}\n:::\n:::\n\n:::\n::: {.column width=\"50%\"}\n\n::: {.cell}\n::: {.cell-output-display}\n![](week4-inference_files/figure-revealjs/unnamed-chunk-5-1.png){width=480}\n:::\n:::\n\n:::\n:::\n\n(Density is an alternative scale to frequency that is independent of population size.)\n\n## Point estimates\n\n> Sample statistics, viewed as guesses for the values of population statistics, are called 'point estimates'.\n\nWe'll focus on inferences involving the following:\n\n| Population statistic     | Parameter | Point estimate |\n|--------------------|--------------------|----------------|\n| Mean               | $\\mu$              | $\\bar{x}$      |\n| Standard deviation | $\\sigma$           | $s_x$          |\n\n## A difficulty\n\n> Different samples yield different estimates.\n\n::: {.columns}\n\n::: {.column width=\"40%\"}\n\n::: {.cell}\n::: {.cell-output-display}\n![](week4-inference_files/figure-revealjs/unnamed-chunk-6-1.png){width=384}\n:::\n:::\n\n:::\n\n::: {.column width=\"60%\"}\nSample means:\n\n::: {.cell}\n::: {.cell-output-display}\n\n---------------------\n sample.1   sample.2 \n---------- ----------\n  5.093      5.136   \n---------------------\n\n\n:::\n:::\n\n\n- estimates are close but not identical\n- the population mean can't be both 5.093 *and* 5.136\n- probably neither estimate is exactly correct\n\n*Estimation error and sample-to-sample variability are inherent to point estimation.*\n:::\n\n:::\n\n\n## Simulating sampling variability\n\n\n::: {.cell}\n\n:::\n\n\n::: columns\n::: {.column width=\"\\\"55%\"}\n\n::: {.cell}\n::: {.cell-output-display}\n![](week4-inference_files/figure-revealjs/unnamed-chunk-9-1.png){width=576}\n:::\n:::\n\n:::\n\n::: {.column width=\"45%\"}\nThese are 20 random samples with the sample mean indicated by the dashed line and the population distribution and mean overlaid in red.\n\n-   sample size $n = 20$\n-   frequency distributions differ a lot\n-   sample means differ some\n\nWe can actually measure this variability!\n\n:::\n:::\n\n## Simulating sampling variability\n\nIf we had means calculated from a much larger number of samples, we could make a frequency distribution for the values of the sample mean.\n\n::: columns\n::: {.column width=\"45%\"}\n\n::: {.cell}\n::: {.cell-output-display}\n![](week4-inference_files/figure-revealjs/unnamed-chunk-10-1.png){width=384}\n:::\n:::\n\n\n------------ ------- ------- ---------- ---------\n **sample**     1       2     $\\cdots$   10,000   \n\n  **mean**    4.957   5.039   $\\cdots$   5.24 \n------------ ------- ------- ---------- ---------\n\n\n:::\n\n::: {.column width=\"55%\"}\nWe could then use the usual measures of center and spread to characterize the distribution of sample means.\n\n-   mean of $\\bar{x}$: 5.0373228\n-   standard deviation of $\\bar{x}$: 0.2387869\n\n> *Across 10,000 random samples of size 20, the typical sample mean was 5.04 and the root average squared distance of the sample mean from its typical value was 0.239.*\n:::\n:::\n\n\n## Sampling distributions\n\nWhat we are simulating is known as a **sampling distribution**: the frequency of values of a statistic across all possible random samples.\n\n::: columns\n::: {.column width=\"45%\"}\n\n::: {.cell}\n::: {.cell-output-display}\n![](week4-inference_files/figure-revealjs/unnamed-chunk-11-1.png){width=480}\n:::\n:::\n\n\n:::\n::: {.column width=\"55%\"}\n\n\n\nProvided data are from a random sample, the sample mean $\\bar{x}$ has a sampling distribution with\n\n- mean $\\color{red}{\\mu}$ (population mean)\n- standard deviation $\\color{red}{\\frac{\\sigma}{\\sqrt{n}}}$\n\nregardless of its exact form.\n\n:::\n\n:::\n\nIn other words, across all random samples of a fixed size...\n\n1. The average value of the sample mean is the population mean.\n2. The average squared error (sample mean - population mean)$^2$ is $\\frac{\\sigma^2}{n}$ \n\n## Effect of sample size\n\nThe standard deviation of the sampling distribution of $\\bar{x}$ is inversely proportional to sample size.\n\n::: {.columns}\n::: {.column width=\"60%\"}\n\n::: {.cell}\n::: {.cell-output-display}\n![](week4-inference_files/figure-revealjs/unnamed-chunk-12-1.png){width=768}\n:::\n:::\n\n:::\n\n::: {.column width=\"40%\"}\n\nAs sample size increases...\n\n- accuracy remains the same\n- estimates get more precise\n- skewness vanishes\n\n:::\n:::\n\n## Measuring sampling variability\n\nIn practice $\\sigma$ is not known so we use an estimate of sampling variability known as a **standard error**: \n$$\nSE(\\bar{x}) = \\frac{s_x}{\\sqrt{n}} \n\\qquad \\left(\\frac{\\text{sample SD}}{\\sqrt{\\text{sample size}}}\\right)\n$$\n\nFor example:\n\n::: columns\n::: {.column width=\"50%\"}\n\n::: {.cell}\n::: {.cell-output-display}\n![](week4-inference_files/figure-revealjs/unnamed-chunk-13-1.png){width=480}\n:::\n:::\n\n:::\n\n::: {.column width=\"50%\"}\n$$\nSE(\\bar{x}) = \\frac{1.073}{\\sqrt{20}} = 0.240\n$$\n\n> The root average squared error of the sample mean is estimated to be 0.240 mmol/L.\n\n:::\n:::\n\n<!-- ## Interpreting standard errors -->\n\n<!-- The standard error is a point estimate of the (population) standard deviation of sample means across all possible random samples: -->\n\n<!-- $$ -->\n<!-- SE(\\bar{x}) \\text{ estimates } \\sqrt{\\text{average value of } (\\bar{x} - \\mu)^2} -->\n<!-- $$ -->\n<!-- Two phrasings for an interpretation: -->\n\n<!-- 1. Estimated root average squared deviation of the sample mean from the population mean. -->\n<!-- 2. Estimated root mean square error. -->\n\n## Reporting point estimates\n\nIt is common style to report the value of a point estimate with a standard error given parenthetically.\n\n::: columns\n::: {.column width=\"50%\"}\nStatistics from full NHANES sample:\n\n::: {.cell}\n::: {.cell-output-display}\n\n----------------------\n mean     sd      n   \n------- ------- ------\n 5.043   1.075   3179 \n----------------------\n\n\n:::\n:::\n\n:::\n\n::: {.column width=\"50%\"}\n\n\n> The mean total cholesterol among the population is estimated to be 5.043 mmol/L (SE 0.019)\n\n:::\n:::\n\nThis style of report communicates:\n\n- parameter of interest\n- value of point estimate\n- error/variability of point estimate\n\n## Interval estimation\n\n> An interval estimate is **a range of plausible values** for a population parameter.\n\nThe general form of an interval estimate is: $$\\text{point estimate} \\pm \\text{margin of error}$$\n\nA common interval for the population mean is:\n$$\\bar{x} \\pm 2\\times SE(\\bar{x}) \\qquad\\text{where}\\quad SE(\\bar{x}) = \\left(\\frac{s_x}{\\sqrt{n}}\\right)$$\n\n::: {.columns}\n\n::: {.column}\nBy hand:\n$$5.043 \\pm 2\\times 0.0191 = (5.005, 5.081)$$\n:::\n\n::: {.column}\nIn R:\n\n::: {.cell}\n\n```{.r .cell-code}\navg.totchol <- mean(totchol)\nse.totchol <- sd(totchol)/sqrt(length(totchol))\navg.totchol + c(-2, 2)*se.totchol\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 5.004817 5.081059\n```\n\n\n:::\n:::\n\n:::\n\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}