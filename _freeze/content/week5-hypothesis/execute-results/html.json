{
  "hash": "5967a5da7a85403ea4e9a6624a655fc8",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Introduction to hypothesis testing\"\nsubtitle: \"One-sample $t$ test for a population mean\"\nformat: \n  revealjs:\n    logo: img/poly-logo-2.jpg\n    footer: \"STAT218\"\n    smaller: true\n    mermaid:\n      theme: neutral\nexecute: \n  echo: false\n  warning: false\n  message: false\neditor: \n  markdown: \n    wrap: 72\n---\n\n::: {.cell}\n\n:::\n\n\n## Today's agenda\n\n1. Loose end: working backwards to determine interval coverage\n2. [lecture] the $t$-test for a population mean\n3. [lab] computing test statistics, critical values, and $p$-values\n\n## Body temperatures\n\n::: columns\n::: {.column width=\"45%\"}\n\n::: {.cell}\n::: {.cell-output-display}\n![](week5-hypothesis_files/figure-revealjs/unnamed-chunk-2-1.png){width=384}\n:::\n\n::: {.cell-output-display}\n\n------------------------------\n mean      sd     n      se   \n------- -------- ---- --------\n 98.41   0.9162   39   0.1467 \n------------------------------\n\n\n:::\n:::\n\n:::\n\n::: {.column width=\"55%\"}\n*Is the true mean body temperature actually 98.6°F?*\n\nSeems plausible given our data.\n\nBut what if the sample mean were instead...\n\n| $\\bar{x}$ | consistent with $\\mu = 98.6$? |\n|-----------|-------------------------------|\n| 98.30     | probably still yes            |\n| 98.15     | maybe                         |\n| 98.00     | hesitating                    |\n| 97.85     | skeptical                     |\n| 97.40     | unlikely                      |\n:::\n:::\n\n> If the estimation error is \"big enough\" the hypothesis seems\n> implausible.\n\n## How much error is too much?\n\nConsider how many standard errors away from the hypothesized value we'd be:\n\n| $\\bar{x}$ | estimation error | no. SE's | interpretation           |\n|-----------|------------------|----------|--------------------------|\n| 98.30     | -0.3             | 2        | double the average error |\n| 98.15     | -0.45            | 3        | triple the average error |\n| 98.00     | -0.6             | 4        | quadruple                |\n| 97.85     | -0.75            | 5        | quintuple                |\n| 97.40     | -1.2             | 8        | octuple!                 |\n\nWe know from discussing confidence intervals that we'd estimate the mean\ntemperature to be within about 2SE of the sample mean, and from interval\ncoverage that:\n\n-   an error less than 2SE occurs for about 95% of samples\n-   an error greater than 2SE occurs for only about 5% of samples\n\n*Exactly how often would we see the error we did if the population mean\nis in fact 98.6°F?*\n\n## Applying the $t$ model\n\n::: columns\n::: column\n***If the population mean is in fact 98.6°F*** then $$\nT = \\frac{\\bar{x} - 98.6}{s_x/\\sqrt{n}}\n\\qquad\\left(\\frac{\\text{estimation error}}{\\text{standard error}}\\right)\n$$ has a sampling distribution that is well-approximated by a\n$t_{39 - 1}$ model.\n:::\n\n::: column\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](week5-hypothesis_files/figure-revealjs/unnamed-chunk-3-1.png){fig-align='center' width=624}\n:::\n:::\n\n:::\n:::\n\n## Applying the $t$ model\n\n\n::: {.cell}\n\n:::\n\n\n::: columns\n::: column\n***If the population mean is in fact 98.6°F*** then $$\nT = \\frac{\\bar{x} - 98.6}{s_x/\\sqrt{n}}\n\\qquad\\left(\\frac{\\text{estimation error}}{\\text{standard error}}\\right)\n$$ has a sampling distribution that is well-approximated by a\n$t_{39 - 1}$ model.\n\n-   actual summary statistics give $T$ = -1.328\n:::\n\n::: column\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](week5-hypothesis_files/figure-revealjs/unnamed-chunk-5-1.png){fig-align='center' width=624}\n:::\n:::\n\n:::\n:::\n\n## Applying the $t$ model\n\n\n::: {.cell}\n\n:::\n\n\n::: columns\n::: column\n***If the population mean is in fact 98.6°F*** then $$\nT = \\frac{\\bar{x} - 98.6}{s_x/\\sqrt{n}}\n\\qquad\\left(\\frac{\\text{estimation error}}{\\text{standard error}}\\right)\n$$ has a sampling distribution that is well-approximated by a\n$t_{39 - 1}$ model.\n\n-   actual summary statistics give $T$ = -1.328\n-   underestimate more in 9.6%\n    of samples\n:::\n\n::: column\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](week5-hypothesis_files/figure-revealjs/unnamed-chunk-7-1.png){fig-align='center' width=624}\n:::\n:::\n\n:::\n:::\n\n## Applying the $t$ model\n\n\n::: {.cell}\n\n:::\n\n\n::: columns\n::: column\n***If the population mean is in fact 98.6°F*** then $$\nT = \\frac{\\bar{x} - 98.6}{s_x/\\sqrt{n}}\n\\qquad\\left(\\frac{\\text{estimation error}}{\\text{standard error}}\\right)\n$$ has a sampling distribution that is well-approximated by a\n$t_{39 - 1}$ model.\n\n-   actual summary statistics give $T$ = -1.328\n-   underestimate more in 9.6%\n    of samples\n-   overestimate more in 9.6%\n    of samples\n:::\n\n::: column\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](week5-hypothesis_files/figure-revealjs/unnamed-chunk-9-1.png){fig-align='center' width=624}\n:::\n:::\n\n:::\n:::\n\n## Applying the $t$ model\n\n\n::: {.cell}\n\n:::\n\n\n::: columns\n::: column\n***If the population mean is in fact 98.6°F*** then $$\nT = \\frac{\\bar{x} - 98.6}{s_x/\\sqrt{n}}\n\\qquad\\left(\\frac{\\text{estimation error}}{\\text{standard error}}\\right)\n$$ has a sampling distribution that is well-approximated by a\n$t_{39 - 1}$ model.\n\n-   actual summary statistics give $T$ = -1.328\n-   underestimate more in 9.6%\n    of samples\n-   overestimate more in 9.6%\n    of samples\n:::\n\n::: column\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](week5-hypothesis_files/figure-revealjs/unnamed-chunk-11-1.png){fig-align='center' width=624}\n:::\n:::\n\n\n$$P(|T| > 1.328) = 0.192$$\n:::\n:::\n\n> We'd see at least as much (absolute) estimation error\n> 19.2% of the time, assuming\n> the hypothesis is true. So this amount of error isn't surprising.\n\n## A more extreme scenario\n\n\n::: {.cell}\n\n:::\n\n\n::: columns\n::: column\n\n***If the population mean is in fact 98.6°F*** then $$\nT = \\frac{\\bar{x} - 98.6}{s_x/\\sqrt{n}}\n\\qquad\\left(\\frac{\\text{estimation error}}{\\text{standard error}}\\right)\n$$ has a sampling distribution that is well-approximated by a\n$t_{39 - 1}$ model.\n\n- suppose instead $\\bar{x} = 98.2$ so $T$ = -2.726\n-   underestimate more in 0.48%\n    of samples\n-   overestimate more in 0.48%\n    of samples\n:::\n\n::: column\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](week5-hypothesis_files/figure-revealjs/unnamed-chunk-13-1.png){fig-align='center' width=624}\n:::\n:::\n\n\n$$P(|T| > 2.726) = 0.0096$$\n:::\n:::\n\n> We'd see at least as much estimation error only\n> 0.96% of the time. So if the\n> hypothesis were true, this sample would be really unusual.\n\n## Evaluating the hypothesis\n\nTo evaluate the hypothesis that $\\mu = 98.6$, we assume it is true and then consider whether the estimation error would be unusually large purely by chance according to the $t$ model:\n\n-   unusually large error $\\longrightarrow$ hypothesis is implausible\n    $\\longrightarrow$ can be rejected\n-   not unusually large error $\\longrightarrow$ hypothesis is plausible\n    $\\longrightarrow$ can't be rejected\n\nWe just made these assessments:\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n---------------------------------------------------------\n sample.mean     se     t.stat   how.often   evaluation  \n------------- -------- -------- ----------- -------------\n    98.41      0.1467   -1.328     0.192     not unusual \n\n    98.2       0.1467   -2.726   0.009632      unusual   \n---------------------------------------------------------\n\n\n:::\n:::\n\n\n*Seems reasonable, but why exactly isn't 19.2% of the time 'unusual'?*\n\n## Decisions, decisions\n\n> What would happen if we decided that $T = -1.328$ was unusual?\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n-------------------------------------------\n sample.mean     se     t.stat   how.often \n------------- -------- -------- -----------\n    98.41      0.1467   -1.328     0.192   \n\n    98.2       0.1467   -2.726   0.009632  \n-------------------------------------------\n\n\n:::\n:::\n\n\nSuppose we drew a line at 20%. Then if in fact $\\mu = 98.6$:\n\n- errors in the 'reject' regime occur by chance 20% of the time\n- so we'll reach the wrong conclusion for 1 in 5 samples\n\nThis error rate is too high.\n\n## Formalizing a test for the mean\n\nA **statistical hypothesis** is a statement about a population\nparameter. For every hypothesis there is an opposing or \"alternative\"\nhypothesis.\n\nA **hypothesis test** is a procedure for deciding between a hypothesis\nand its alternative.\n\n::: columns\n::: {.column width=\"60%\"}\nWe just tested the hypotheses: \n\n$$\n\\begin{cases}\nH_0: &\\mu = 98.6 \\quad(\\text{\"null\" hypothesis}) \\\\\nH_A: &\\mu \\neq 98.6 \\quad(\\text{\"alternative\" hypothesis})\n\\end{cases}\n$$\n\nOur decision was based on the \"test statistic\":\n\n$$\nT = \\frac{\\bar{x} - 98.6}{SE(\\bar{x})}\n$$\n\nIf $H_0$ is true, the sampling distribution of $T$ is well-approximated\nby a $t_{n-1}$ model.\n:::\n\n::: {.column width=\"40%\"}\nWe reject $H_0$ if it entails that the estimation error is unusually large relative to the standard error.\n\n- 'unusual' determined by considering error rate\n- two equivalent approaches: \n\n    1. critical values \n    2. $p$-values\n:::\n:::\n\n## The critical value approach\n\n> Reject $H_0$ if $|T|$ exceeds the $1 - \\frac{\\alpha}{2}$ quantile of the $t_{n - 1}$ model\n\n::: {.columns}\n::: {.column width=\"45%\"}\nSteps:\n\n1. Decide on an error tolerance $\\alpha$.\n2. Find the $1 - \\frac{\\alpha}{2}$ quantile $q$.\n3. Reject if $|T| > q$.\n\n:::\n\n::: {.column width=\"55%\"}\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# compute test statistic\ntstat <- (temp.mean - 98.6)/temp.mean.se\ntstat\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -1.328265\n```\n\n\n:::\n\n```{.r .cell-code}\n# compute critical value for a 5% error tolerance\ncrit.val <- qt(p = 0.975, df = 38)\ncrit.val\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 2.024394\n```\n\n\n:::\n\n```{.r .cell-code}\n# compare\nabs(tstat) > crit.val \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] FALSE\n```\n\n\n:::\n:::\n\n\n:::\n\n:::\n\nRationale: if $H_0$ is true...\n\n- $|T|$ will be smaller than the quantile for $(1 - \\alpha)\\times 100$% of samples\n- so using this rule you'll only make a mistake $\\alpha\\times 100$% of the time\n\n\n## The $p$-value approach\n\n> Reject $H_0$ if $T$ exceeds the observed value for less than $\\alpha\\times 100$% of samples: $$2\\times P(T > |T_\\text{obs}|) < \\alpha$$\n\n::: {.columns}\n\n::: {.column width=\"45%\"}\nSteps:\n\n1. Decide on an error tolerance $\\alpha$.\n2. Compute the proportion $p$ of samples for which $T$ exceeds observed value.\n3. Reject if $p < \\alpha$.\n:::\n\n::: {.column width=\"55%\"}\n\n::: {.cell}\n\n```{.r .cell-code}\n# compute test statistic\ntstat <- (temp.mean - 98.6)/temp.mean.se\ntstat\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -1.328265\n```\n\n\n:::\n\n```{.r .cell-code}\n# proportion of samples where T exceeds observed value\np.val <- 2*pt(abs(tstat), df = 38, lower.tail = F)\np.val\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.1920133\n```\n\n\n:::\n\n```{.r .cell-code}\n# decision with error rate controlled at 5%\np.val < 0.05\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] FALSE\n```\n\n\n:::\n:::\n\n:::\n\n:::\n\nRationale: \n\n- $p$-value conveys exactly how unusual the test statistic is\n- $p < \\alpha$ exactly when $|T| > q$, so this rule controls the error rate at $\\alpha$\n\n## Test outcomes\n\nThere are two possible findings for a test:\n\n-   \\[crosses decision threshold\\] reject $H_0$ in favor of $H_A$\n-   \\[doesn't cross decision threshold\\] fail to reject $H_0$ in favor of $H_A$\n\nA **reject** decision is interpreted as:\n\n> The data provide evidence that... \\[against $H_0$/favoring $H_A$\\]\n\nA **fail to reject** decision is interpreted as:\n\n> The data *do not* provide evidence that... \\[against $H_0$/favoring\n> $H_A$\\]\n\n## Interpreting results\n\n::: columns\n::: {.column width=\"55%\"}\nCalculations in R:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# compute test statistic\ntstat <- (temp.mean - 98.6)/temp.mean.se\ntstat\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -1.328265\n```\n\n\n:::\n\n```{.r .cell-code}\n# compute critical value for a 5% error tolerance\ncrit.val <- qt(p = 0.975, df = 38)\ncrit.val\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 2.024394\n```\n\n\n:::\n\n```{.r .cell-code}\n# test decision\nabs(tstat) > crit.val\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] FALSE\n```\n\n\n:::\n\n```{.r .cell-code}\n# p-value\n2*pt(abs(tstat), df = 38, lower.tail = F)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.1920133\n```\n\n\n:::\n:::\n\n:::\n\n::: {.column width=\"45%\"}\nConventional narrative summary style:\n\n> The data do not provide evidence that the mean body temperature differs from 98.6°F (*T* = -1.328 on 38 degrees of freedom, *p* = 0.192).\n\nConveys a lot of info succinctly:\n\n- test conclusion\n- hypotheses tested\n- number of standard errors from hypothesized value ($T$)\n- sample size (degrees of freedom + 1)\n- strength of evidence ($p$-value)\n:::\n:::\n\n<!-- ## Significance conventions -->\n\n<!-- ::: {.columns} -->\n\n<!-- ::: {.column width=\"43%\"} -->\n\n<!-- **Convention 1:** statistical significance -->\n\n<!-- - $p < 0.05$: reject $H_0$ -->\n\n<!-- - $p \\geq 0.05$: fail to reject $H_0$ -->\n\n<!-- > \"The data provide **significant evidence at level $\\alpha$ = 0.05** against the hypothesis that mean body temperature is 98.6 °F in favor of the alternative that mean body temperature differs from 98.6 °F (*T* = -5.4548 on 129 degrees of freedom, *p* = .0000002411).\" -->\n\n<!-- ::: -->\n\n<!-- ::: {.column width=\"57%\"} -->\n\n<!-- **Convention 2:** weight of evidence against $H_0$ -->\n\n<!-- - $p < 0.01$: strong evidence -->\n\n<!-- - $0.01 \\leq p < 0.05$: moderate evidence -->\n\n<!-- - $0.05 \\leq p < 0.1$: weak evidence  -->\n\n<!-- - $0.1 \\leq p$: no evidence -->\n\n<!-- > \"The data **provide strong evidence** against the hypothesis that mean body temperature is 98.6 °F in favor of the alternative that mean body temperature differs from 98.6 °F (*T* = -5.4548 on 129 degrees of freedom, *p* = .0000002411).\" -->\n\n<!-- ::: -->\n\n<!-- ::: -->\n\n<!-- You may use either convention to interpret test results. -->\n\n## Components of a test\n\n| Component              | Explanation                                                                  | Example                                                     |\n|----------------|--------------------------------|-------------------------|\n| Population parameter   | The quantity of interest                                                     | Mean body temp $\\mu$                                        |\n| Null hypothesis        | The claim to be tested                                                       | $\\mu = 98.6$                                                |\n| Alternative hypothesis | The alternative claim                                                        | $\\mu \\neq 98.6$                                             |\n| Test statistic         | A function of the sample data and the hypothetical parameter value | $T = \\frac{\\bar{x} - 98.6}{s_x/\\sqrt{n}} = -1.328$          |\n| Model                  | Sampling distribution of the test statistic under $H_0$                      | $t_{38}$ model                                              |\n| $p$-value              | Probability under $H_0$ of obtaining a result at least as favorable to $H_A$ | 19.2% of samples produce a test statistic at least as large |\n| Decision               | Reject or fail to reject $H_0$ in favor of $H_A$                             | Fail to reject                                              |\n",
    "supporting": [
      "week5-hypothesis_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}